{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time, wget, csv, string, time, random\n",
    "import itertools, collections\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GaussianNoise, Dropout, Dense, Embedding, MaxPool1D, GlobalMaxPool1D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier for Cardiovascular Disease using a Convolutional Neural Network\n",
    "\n",
    "In this notebook, we will be building a model for classifying a sentence from an EHR note for the presence of cardiovascular disease. The model will be trained using a convoultional neural network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other', 'PAST MEDICAL HISTORY:, He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, and lifting objects off the floor.  He exercises three times a week at home and does cardio.  He has difficulty walking two blocks or five flights of stairs.  Difficulty with snoring.  He has muscle and joint pains including knee pain, back pain, foot and ankle pain, and swelling.  He has gastroesophageal reflux disease.,PAST SURGICAL HISTORY:, Includes reconstructive surgery on his right hand 13 years ago.  ,SOCIAL HISTORY:, He is currently single.  He has about ten drinks a year.  He had smoked significantly up until several months ago.  He now smokes less than three cigarettes a day.,FAMILY HISTORY:, Heart disease in both grandfathers, grandmother with stroke, and a grandmother with diabetes.  Denies obesity and hypertension in other family members.,CURRENT MEDICATIONS:, None.,ALLERGIES:,  He is allergic to Penicillin.,MISCELLANEOUS/EATING HISTORY:, He has been going to support groups for seven months with Lynn Holmberg in Greenwich and he is from Eastchester, New York and he feels that we are the appropriate program.  He had a poor experience with the Greenwich program.  Eating history, he is not an emotional eater.  Does not like sweets.  He likes big portions and carbohydrates.  He likes chicken and not steak.  He currently weighs 312 pounds.  Ideal body weight would be 170 pounds.  He is 142 pounds overweight.  If ,he lost 60% of his excess body weight that would be 84 pounds and he should weigh about 228.,REVIEW OF SYSTEMS: ,Negative for head, neck, heart, lungs, GI, GU, orthopedic, and skin.  Specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, CVA, venous insufficiency, thrombophlebitis, asthma, shortness of breath, COPD, emphysema, sleep apnea, diabetes, leg and foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  Denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:, He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Afebrile.  Vital Signs are stable.']\n",
      "['Cardiovascular', '2-D M-MODE: , ,1.  Left atrial enlargement with left atrial diameter of 4.7 cm.,2.  Normal size right and left ventricle.,3.  Normal LV systolic function with left ventricular ejection fraction of 51%.,4.  Normal LV diastolic function.,5.  No pericardial effusion.,6.  Normal morphology of aortic valve, mitral valve, tricuspid valve, and pulmonary valve.,7.  PA systolic pressure is 36 mmHg.,DOPPLER: , ,1.  Mild mitral and tricuspid regurgitation.,2.  Trace aortic and pulmonary regurgitation.']\n"
     ]
    }
   ],
   "source": [
    "ehr_notes = []\n",
    "with open('data/ehr_samples.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:     \n",
    "        if int(row['SpecialtyID']) in [39, 6, 16, 37, 11, 12, 29, 26, 7, 21, 19, 10, 2, 18]:\n",
    "            continue\n",
    "        elif int(row['SpecialtyID']) != 4:\n",
    "            ehr_notes.append(['Other', row['Note']])\n",
    "        else:\n",
    "            ehr_notes.append([row['Specialty'], row['Note']])\n",
    "\n",
    "print(ehr_notes[0])\n",
    "print(ehr_notes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Langauge Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular', 'return clinic 4 weeks5']\n",
      "['Other', 'biceps tendon nonsubluxable']\n"
     ]
    }
   ],
   "source": [
    "ehr_sentences = []\n",
    "for record in ehr_notes:\n",
    "    sent_text = nltk.sent_tokenize(record[1])\n",
    "    for sent in sent_text:\n",
    "        tokens = word_tokenize(sent)\n",
    "\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "        # filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "#         # stem words\n",
    "#         porter = PorterStemmer()\n",
    "#         tokens = [porter.stem(word) for word in tokens]\n",
    "\n",
    "        # remove blanks\n",
    "        tokens = [w for w in tokens if w != '']\n",
    "\n",
    "        ehr_sentences.append([record[0], ' '.join(tokens)])\n",
    "\n",
    "random.Random(4).shuffle(ehr_sentences)\n",
    "\n",
    "print(ehr_sentences[0])\n",
    "print(ehr_sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "\n",
    "The first step is to load in our word embedding, which is trained on text from Wikipedia, Pubmed, and Pubmed Central. We load our word embedding through a tool called Magnitude. A full exploration of the word embedding and Magnitude can be found in the Introduction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = list(np.array(ehr_sentences)[:,1])\n",
    "lengths = [len(note.split(' ')) for note in notes]\n",
    "MAX_WORDS = max(lengths) # The maximum number of words the sequence model will consider\n",
    "med_vectors = Magnitude(\"data/wikipedia-pubmed-and-PMC-w2v.magnitude\", pad_to_length=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Training and Test Data\n",
    "\n",
    "Before we can start building our neural networks, we first have to define our datasets. Specifically, we have to break up our EHR data so that we have records that we can train on and records that are exclusively used to test on. Maintaining a separate set for testing ensures we avoid overfitting our data.\n",
    "\n",
    "We will use some built-in functions provided by Magnitude that helps encode our classes/categories. We then partition our data into our train and test sets. For each set we have both data and labels. Initially, we will be making these partitions small to make iterating through model development much quicker. However, once the models are developed, we will expand our datasets to include all of our data. To ensure we defined our data correctly, we can print a few lines from the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ehr_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiovascular\n",
      "First line of train/test data:\n",
      "\t ['return', 'clinic', '4', 'weeks5']\n",
      "\t 0 Cardiovascular\n",
      "\t ['smokes', 'one', 'pack', 'per', 'day']\n",
      "\t 0 Cardiovascular\n",
      "Second line of train/test data:\n",
      "\t ['biceps', 'tendon', 'nonsubluxable']\n",
      "\t 1 Other\n",
      "\t ['denies', 'illicit', 'drug', 'use', 'family', 'history', 'parents', 'died', 'myocardial', 'infarctions']\n",
      "\t 1 Other\n"
     ]
    }
   ],
   "source": [
    "add_intent, intent_to_int, int_to_intent = MagnitudeUtils.class_encoding()\n",
    "\n",
    "x_train = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[:60000]]\n",
    "x_test = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[60001:]]\n",
    "\n",
    "y_train = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[:60000]]\n",
    "y_test = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[60001:]]\n",
    "\n",
    "y_train = list(np.array(y_train).reshape(len(y_train)))\n",
    "y_test = list(np.array(y_test).reshape(len(y_test)))\n",
    "\n",
    "num_training = len(x_train)\n",
    "num_test = len(x_test)\n",
    "num_outputs = int(max(max(y_train), max(y_test))) + 1\n",
    "\n",
    "print(int_to_intent(0))\n",
    "\n",
    "print(\"First line of train/test data:\")\n",
    "print(\"\\t\", x_train[0])\n",
    "print(\"\\t\", y_train[0], int_to_intent(y_train[0]))\n",
    "print(\"\\t\", x_test[0])\n",
    "print(\"\\t\", y_test[0], int_to_intent(y_test[0]))\n",
    "print(\"Second line of train/test data:\")\n",
    "print(\"\\t\", x_train[1])\n",
    "print(\"\\t\", y_train[1], int_to_intent(y_train[1]))\n",
    "print(\"\\t\", x_test[1])\n",
    "print(\"\\t\", y_test[1], int_to_intent(y_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Custom Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 163, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 163, 128)          179328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 81, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 81, 128)           114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 302,530\n",
      "Trainable params: 302,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "STD_DEV = 0.01 # Deviation of noise for Gaussian Noise applied to the embeddings\n",
    "DROPOUT_RATIO = .5 # The ratio to dropout\n",
    "BATCH_SIZE = 100 # The number of examples per train/validation step\n",
    "EPOCHS = 100 # The number of times to repeat through all of the training data\n",
    "LEARNING_RATE = .01 # The learning rate for the optimizer\n",
    "NUM_FILTERS = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(STD_DEV, input_shape=(MAX_WORDS, med_vectors.dim)))\n",
    "model.add(Conv1D(NUM_FILTERS, 7, activation='relu', padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(NUM_FILTERS, 7, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(DROPOUT_RATIO))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Batches and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1242s 2s/step - loss: 0.3301 - acc: 0.8679 - f1: 0.8679 - val_loss: 0.3014 - val_acc: 0.8830 - val_f1: 0.8830\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.2780 - acc: 0.8897 - f1: 0.8897 - val_loss: 0.2835 - val_acc: 0.8856 - val_f1: 0.8856\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.2399 - acc: 0.9039 - f1: 0.9039 - val_loss: 0.2863 - val_acc: 0.8846 - val_f1: 0.8846\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 161s 268ms/step - loss: 0.2039 - acc: 0.9158 - f1: 0.9158 - val_loss: 0.3061 - val_acc: 0.8794 - val_f1: 0.8794\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 158s 263ms/step - loss: 0.1748 - acc: 0.9256 - f1: 0.9256 - val_loss: 0.3321 - val_acc: 0.8618 - val_f1: 0.8618\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.1576 - acc: 0.9328 - f1: 0.9328 - val_loss: 0.3645 - val_acc: 0.8385 - val_f1: 0.8385\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.1477 - acc: 0.9359 - f1: 0.9359 - val_loss: 0.3731 - val_acc: 0.8591 - val_f1: 0.8591\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.1336 - acc: 0.9432 - f1: 0.9432 - val_loss: 0.4143 - val_acc: 0.8679 - val_f1: 0.8679\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 156s 260ms/step - loss: 0.1225 - acc: 0.9467 - f1: 0.9467 - val_loss: 0.4705 - val_acc: 0.8729 - val_f1: 0.8729\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.1152 - acc: 0.9497 - f1: 0.9497 - val_loss: 0.4695 - val_acc: 0.8585 - val_f1: 0.8585\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.1121 - acc: 0.9506 - f1: 0.9506 - val_loss: 0.4588 - val_acc: 0.8531 - val_f1: 0.8531\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.1072 - acc: 0.9524 - f1: 0.9523 - val_loss: 0.5217 - val_acc: 0.8526 - val_f1: 0.8526\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.1049 - acc: 0.9531 - f1: 0.9530 - val_loss: 0.5268 - val_acc: 0.8619 - val_f1: 0.8619\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 158s 263ms/step - loss: 0.0960 - acc: 0.9557 - f1: 0.9557 - val_loss: 0.5750 - val_acc: 0.8522 - val_f1: 0.8522\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0954 - acc: 0.9555 - f1: 0.9555 - val_loss: 0.5723 - val_acc: 0.8590 - val_f1: 0.8590\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0918 - acc: 0.9570 - f1: 0.9570 - val_loss: 0.5990 - val_acc: 0.8622 - val_f1: 0.8622\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 159s 266ms/step - loss: 0.0899 - acc: 0.9576 - f1: 0.9576 - val_loss: 0.6814 - val_acc: 0.8659 - val_f1: 0.8659\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0867 - acc: 0.9584 - f1: 0.9584 - val_loss: 0.6356 - val_acc: 0.8664 - val_f1: 0.8664\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0879 - acc: 0.9573 - f1: 0.9573 - val_loss: 0.7700 - val_acc: 0.8686 - val_f1: 0.8686\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0825 - acc: 0.9586 - f1: 0.9586 - val_loss: 0.6931 - val_acc: 0.8676 - val_f1: 0.8676\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0845 - acc: 0.9581 - f1: 0.9581 - val_loss: 0.7408 - val_acc: 0.8667 - val_f1: 0.8667\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0803 - acc: 0.9606 - f1: 0.9606 - val_loss: 0.7934 - val_acc: 0.8693 - val_f1: 0.8693\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0807 - acc: 0.9594 - f1: 0.9594 - val_loss: 0.7315 - val_acc: 0.8637 - val_f1: 0.8637\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0788 - acc: 0.9610 - f1: 0.9610 - val_loss: 0.7605 - val_acc: 0.8664 - val_f1: 0.8664\n",
      "Epoch 27/100\n",
      "148/600 [======>.......................] - ETA: 1:50 - loss: 0.0762 - acc: 0.9616 - f1: 0.9616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 158s 263ms/step - loss: 0.0760 - acc: 0.9616 - f1: 0.9616 - val_loss: 0.7272 - val_acc: 0.8623 - val_f1: 0.8623\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0757 - acc: 0.9610 - f1: 0.9610 - val_loss: 0.7417 - val_acc: 0.8612 - val_f1: 0.8612\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0768 - acc: 0.9607 - f1: 0.9607 - val_loss: 0.7611 - val_acc: 0.8626 - val_f1: 0.8626\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 156s 260ms/step - loss: 0.0739 - acc: 0.9618 - f1: 0.9618 - val_loss: 0.8083 - val_acc: 0.8635 - val_f1: 0.8635\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0729 - acc: 0.9619 - f1: 0.9619 - val_loss: 0.8112 - val_acc: 0.8597 - val_f1: 0.8597\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 156s 260ms/step - loss: 0.0733 - acc: 0.9621 - f1: 0.9621 - val_loss: 0.8128 - val_acc: 0.8664 - val_f1: 0.8664\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 159s 266ms/step - loss: 0.0727 - acc: 0.9614 - f1: 0.9614 - val_loss: 0.8212 - val_acc: 0.8691 - val_f1: 0.8691\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0700 - acc: 0.9632 - f1: 0.9632 - val_loss: 0.8768 - val_acc: 0.8661 - val_f1: 0.8661\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0706 - acc: 0.9625 - f1: 0.9625 - val_loss: 0.8947 - val_acc: 0.8682 - val_f1: 0.8682\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0698 - acc: 0.9629 - f1: 0.9628 - val_loss: 0.8589 - val_acc: 0.8654 - val_f1: 0.8654\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0690 - acc: 0.9629 - f1: 0.9629 - val_loss: 0.9828 - val_acc: 0.8702 - val_f1: 0.8702\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0706 - acc: 0.9623 - f1: 0.9623 - val_loss: 0.8844 - val_acc: 0.8651 - val_f1: 0.8651\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.0687 - acc: 0.9632 - f1: 0.9632 - val_loss: 0.8961 - val_acc: 0.8670 - val_f1: 0.8670\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0674 - acc: 0.9634 - f1: 0.9634 - val_loss: 0.9679 - val_acc: 0.8691 - val_f1: 0.8691\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0665 - acc: 0.9644 - f1: 0.9644 - val_loss: 0.9183 - val_acc: 0.8678 - val_f1: 0.8678\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0658 - acc: 0.9649 - f1: 0.9649 - val_loss: 0.9377 - val_acc: 0.8683 - val_f1: 0.8683\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0669 - acc: 0.9636 - f1: 0.9636 - val_loss: 0.9112 - val_acc: 0.8680 - val_f1: 0.8680\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0675 - acc: 0.9635 - f1: 0.9635 - val_loss: 0.9305 - val_acc: 0.8686 - val_f1: 0.8686\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0662 - acc: 0.9638 - f1: 0.9638 - val_loss: 0.9162 - val_acc: 0.8629 - val_f1: 0.8629\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0652 - acc: 0.9650 - f1: 0.9650 - val_loss: 0.9223 - val_acc: 0.8657 - val_f1: 0.8657\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0652 - acc: 0.9639 - f1: 0.9639 - val_loss: 0.9464 - val_acc: 0.8636 - val_f1: 0.8636\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0657 - acc: 0.9639 - f1: 0.9639 - val_loss: 0.9405 - val_acc: 0.8689 - val_f1: 0.8689\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0650 - acc: 0.9644 - f1: 0.9644 - val_loss: 0.9662 - val_acc: 0.8683 - val_f1: 0.8683\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0627 - acc: 0.9646 - f1: 0.9646 - val_loss: 0.9929 - val_acc: 0.8653 - val_f1: 0.8653\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0631 - acc: 0.9656 - f1: 0.9656 - val_loss: 0.9676 - val_acc: 0.8668 - val_f1: 0.8668\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.0659 - acc: 0.9639 - f1: 0.9639 - val_loss: 0.8969 - val_acc: 0.8651 - val_f1: 0.8651\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0631 - acc: 0.9653 - f1: 0.9653 - val_loss: 0.9613 - val_acc: 0.8644 - val_f1: 0.8644\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0627 - acc: 0.9645 - f1: 0.9644 - val_loss: 1.0075 - val_acc: 0.8655 - val_f1: 0.8655\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0636 - acc: 0.9637 - f1: 0.9637 - val_loss: 0.9750 - val_acc: 0.8638 - val_f1: 0.8638\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0620 - acc: 0.9645 - f1: 0.9645 - val_loss: 0.9617 - val_acc: 0.8635 - val_f1: 0.8635\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0621 - acc: 0.9653 - f1: 0.9653 - val_loss: 1.0093 - val_acc: 0.8670 - val_f1: 0.8670\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 161s 268ms/step - loss: 0.0617 - acc: 0.9660 - f1: 0.9660 - val_loss: 1.0229 - val_acc: 0.8645 - val_f1: 0.8645\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0610 - acc: 0.9653 - f1: 0.9653 - val_loss: 1.0148 - val_acc: 0.8674 - val_f1: 0.8674\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.0638 - acc: 0.9640 - f1: 0.9640 - val_loss: 0.9967 - val_acc: 0.8692 - val_f1: 0.8692\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 156s 260ms/step - loss: 0.0608 - acc: 0.9655 - f1: 0.9655 - val_loss: 1.0009 - val_acc: 0.8654 - val_f1: 0.8654\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0617 - acc: 0.9648 - f1: 0.9647 - val_loss: 1.0033 - val_acc: 0.8665 - val_f1: 0.8665\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0619 - acc: 0.9649 - f1: 0.9649 - val_loss: 1.0372 - val_acc: 0.8671 - val_f1: 0.8671\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0609 - acc: 0.9658 - f1: 0.9658 - val_loss: 1.0463 - val_acc: 0.8648 - val_f1: 0.8648\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0613 - acc: 0.9650 - f1: 0.9650 - val_loss: 1.0325 - val_acc: 0.8665 - val_f1: 0.8665\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0605 - acc: 0.9648 - f1: 0.9648 - val_loss: 1.0425 - val_acc: 0.8670 - val_f1: 0.8670\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0611 - acc: 0.9651 - f1: 0.9651 - val_loss: 0.9974 - val_acc: 0.8680 - val_f1: 0.8680\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 158s 263ms/step - loss: 0.0609 - acc: 0.9661 - f1: 0.9661 - val_loss: 1.0186 - val_acc: 0.8664 - val_f1: 0.8664\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0597 - acc: 0.9652 - f1: 0.9652 - val_loss: 1.0961 - val_acc: 0.8649 - val_f1: 0.8649\n",
      "Epoch 71/100\n",
      "517/600 [========================>.....] - ETA: 20s - loss: 0.0602 - acc: 0.9648 - f1: 0.9648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 155s 258ms/step - loss: 0.0596 - acc: 0.9657 - f1: 0.9657 - val_loss: 1.0621 - val_acc: 0.8682 - val_f1: 0.8682\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0602 - acc: 0.9657 - f1: 0.9657 - val_loss: 1.0328 - val_acc: 0.8661 - val_f1: 0.8661\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 160s 266ms/step - loss: 0.0589 - acc: 0.9657 - f1: 0.9657 - val_loss: 1.1133 - val_acc: 0.8665 - val_f1: 0.8665\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0593 - acc: 0.9659 - f1: 0.9659 - val_loss: 1.0653 - val_acc: 0.8679 - val_f1: 0.8679\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0592 - acc: 0.9654 - f1: 0.9654 - val_loss: 1.0739 - val_acc: 0.8671 - val_f1: 0.8671\n",
      "Epoch 78/100\n",
      "321/600 [===============>..............] - ETA: 1:10 - loss: 0.0578 - acc: 0.9666 - f1: 0.9666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0586 - acc: 0.9659 - f1: 0.9659 - val_loss: 1.0079 - val_acc: 0.8648 - val_f1: 0.8648\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 159s 266ms/step - loss: 0.0596 - acc: 0.9652 - f1: 0.9652 - val_loss: 0.9935 - val_acc: 0.8627 - val_f1: 0.8627\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0575 - acc: 0.9663 - f1: 0.9663 - val_loss: 0.9765 - val_acc: 0.8665 - val_f1: 0.8665\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0600 - acc: 0.9659 - f1: 0.9659 - val_loss: 1.0602 - val_acc: 0.8696 - val_f1: 0.8696\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 158s 263ms/step - loss: 0.0571 - acc: 0.9661 - f1: 0.9661 - val_loss: 1.0570 - val_acc: 0.8663 - val_f1: 0.8663\n",
      "Epoch 85/100\n",
      "139/600 [=====>........................] - ETA: 1:53 - loss: 0.0572 - acc: 0.9652 - f1: 0.9652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0586 - acc: 0.9658 - f1: 0.9658 - val_loss: 1.0982 - val_acc: 0.8654 - val_f1: 0.8654\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0581 - acc: 0.9661 - f1: 0.9661 - val_loss: 1.0719 - val_acc: 0.8594 - val_f1: 0.8594\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0577 - acc: 0.9665 - f1: 0.9665 - val_loss: 1.0762 - val_acc: 0.8628 - val_f1: 0.8628\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 159s 266ms/step - loss: 0.0567 - acc: 0.9672 - f1: 0.9672 - val_loss: 1.0375 - val_acc: 0.8639 - val_f1: 0.8639\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 158s 263ms/step - loss: 0.0577 - acc: 0.9665 - f1: 0.9665 - val_loss: 1.1314 - val_acc: 0.8673 - val_f1: 0.8673\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0580 - acc: 0.9655 - f1: 0.9655 - val_loss: 1.1047 - val_acc: 0.8655 - val_f1: 0.8655\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 157s 261ms/step - loss: 0.0577 - acc: 0.9663 - f1: 0.9663 - val_loss: 1.0720 - val_acc: 0.8649 - val_f1: 0.8649\n",
      "Epoch 93/100\n",
      "162/600 [=======>......................] - ETA: 1:48 - loss: 0.0555 - acc: 0.9675 - f1: 0.9675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 161s 269ms/step - loss: 0.0568 - acc: 0.9670 - f1: 0.9670 - val_loss: 1.0593 - val_acc: 0.8669 - val_f1: 0.8669\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 158s 264ms/step - loss: 0.0581 - acc: 0.9662 - f1: 0.9662 - val_loss: 1.0934 - val_acc: 0.8638 - val_f1: 0.8638\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 157s 262ms/step - loss: 0.0559 - acc: 0.9671 - f1: 0.9671 - val_loss: 1.1695 - val_acc: 0.8659 - val_f1: 0.8659\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 159s 265ms/step - loss: 0.0573 - acc: 0.9658 - f1: 0.9658 - val_loss: 1.1058 - val_acc: 0.8661 - val_f1: 0.8661\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 156s 260ms/step - loss: 0.0572 - acc: 0.9667 - f1: 0.9666 - val_loss: 1.1661 - val_acc: 0.8649 - val_f1: 0.8649\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 159s 264ms/step - loss: 0.0580 - acc: 0.9666 - f1: 0.9666 - val_loss: 1.1277 - val_acc: 0.8694 - val_f1: 0.8694\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 160s 267ms/step - loss: 0.0573 - acc: 0.9657 - f1: 0.9656 - val_loss: 1.1614 - val_acc: 0.8692 - val_f1: 0.8692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e58c7e2b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_batches = MagnitudeUtils.batchify(x_train, y_train, BATCH_SIZE) # Split the training data into batches\n",
    "num_batches_per_epoch_train = int(np.ceil(num_training/float(BATCH_SIZE)))\n",
    "test_batches = MagnitudeUtils.batchify(x_test, y_test, BATCH_SIZE)  # Split the test data into batches\n",
    "num_batches_per_epoch_test = int(np.ceil(num_test/float(BATCH_SIZE)))\n",
    "\n",
    "\n",
    "# Generates batches of the transformed training data\n",
    "train_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_train_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_train_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_train_batch, y_train_batch in training_batches\n",
    ")\n",
    "\n",
    "# Generates batches of the transformed test data\n",
    "test_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_test_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_test_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_test_batch, y_test_batch in test_batches\n",
    ")\n",
    "\n",
    "# Start training\n",
    "model.fit_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps_per_epoch = num_batches_per_epoch_train,\n",
    "    validation_data = test_batch_generator,\n",
    "    validation_steps = num_batches_per_epoch_test,\n",
    "    epochs = EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after training for 100 epochs:\n",
      "loss: 0.0509 - categorical_accuracy: 0.9680 - f1: 0.9680\n",
      "val_loss: 1.1614 - val_categorical_accuracy: 0.8692 - f1: 0.8692\n"
     ]
    }
   ],
   "source": [
    "print(\"Results after training for %d epochs:\" % (EPOCHS,))\n",
    "\n",
    "train_metrics = model.evaluate_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps = num_batches_per_epoch_train,\n",
    ")\n",
    "\n",
    "print(\"loss: %.4f - categorical_accuracy: %.4f - f1: %.4f\" % tuple(train_metrics))\n",
    "\n",
    "val_metrics = model.evaluate_generator(\n",
    "    generator = test_batch_generator,\n",
    "    steps = num_batches_per_epoch_test,\n",
    ")\n",
    "\n",
    "print(\"val_loss: %.4f - val_categorical_accuracy: %.4f - f1: %.4f\" % tuple(val_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular', 'Other']\n",
      "[[ 692  985]\n",
      " [ 446 8817]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Cardiovascular       0.61      0.41      0.49      1677\n",
      "         Other       0.90      0.95      0.92      9263\n",
      "\n",
      "   avg / total       0.85      0.87      0.86     10940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(med_vectors.query(x_test)), axis=1)\n",
    "class_labels = [int_to_intent(y) for y in set(y_test)] \n",
    "report = classification_report(y_test, y_pred, target_names=class_labels)\n",
    "print(class_labels)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e49808cf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = [int_to_intent(y_class) for y_class in unique_labels(y_test, y_pred)]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "#     fig.set_figheight(15)\n",
    "#     fig.set_figwidth(15)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_labels\n",
    "                      , title='Confusion Matrix for Cardiovascular Disease CNN Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
