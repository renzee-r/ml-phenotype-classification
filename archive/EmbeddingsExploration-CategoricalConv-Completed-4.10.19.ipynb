{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time, wget, csv, string, time, random\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GaussianNoise, LSTM, Bidirectional, Dropout, Dense, Embedding, MaxPool1D, GlobalMaxPool1D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "## Phenotype Classification of Electronic Health Records\n",
    "\n",
    "Electronic Health Record (EHR) data is a rapidly growing source of unstructured biomedical data. This data is extremely rich, often capturing a patientâ€™s phenotype. In a clinical context, phenotype refers to the specific medical condition or disease of a patient. These records captures this data in higher detail compared to structured encodings such as the International Classification of Diseases (ICD) or National Drug Codes (NDC). Traditional methods for extracting phenotypes from this data typically relies on manual review or processing the data through rule-based expert systems. Both approaches are time intensive, rely heavily on human expertise, and scale poorly with increased volume. This project proposes an automated approach to identifying phenotypes in EHR data through word vector clustering and machine learning. An automated approach would greatly reduce time and operation costs, with the potential of even outperforming industry standards. \n",
    "\n",
    "The data for this project is provided by nlplab, who have induced a biomedical corpus using word2vec. This corpus contains over 5 billion words pulled from biomedical scientific literature and Wikipedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION\n",
    "## Word Embedding\n",
    "\n",
    "The foundation of this project is based on word embedding models, an approach that converts words into number vectors based on co-occurence. These vectors help capture word meanings and context in a format suitable for machine learning. \n",
    "\n",
    "Typically these vectors are trained on extremely large corpora, which can take a lot of time and resources. Thankfully, the word embedding space is quite mature and there exists pre-trained models, ready to use out of the box. One such model is Standford's GloVe vectors, which is trained on a corpus of 6B tokens from Wikipedia and Gigaword. These vectors are available at https://nlp.stanford.edu/projects/glove/. We will go through some exercises to explore word vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n"
     ]
    }
   ],
   "source": [
    "import glove_helper; reload(glove_helper)\n",
    "hands = glove_helper.Hands(ndim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn_cos(v, Wv, k=10):\n",
    "    \"\"\"Find nearest neighbors of a given word, by cosine similarity.\n",
    "    \n",
    "    Returns two parallel lists: indices of nearest neighbors, and \n",
    "    their cosine similarities. Both lists are in descending order, \n",
    "    and inclusive: so nns[0] should be the index of the input word, \n",
    "    nns[1] should be the index of the first nearest neighbor, and so on.\n",
    "\n",
    "    Args:\n",
    "      v: (d-dimensional vector) word vector of interest\n",
    "      Wv: (V x d matrix) word embeddings\n",
    "      k: (int) number of neighbors to return\n",
    "    \n",
    "    Returns (nns, ds), where:\n",
    "      nns: (k-dimensional vector of int), row indices of nearest neighbors, \n",
    "        which may include the given word.\n",
    "      similarities: (k-dimensional vector of float), cosine similarity of each \n",
    "        neighbor in nns.\n",
    "    \"\"\"\n",
    "\n",
    "    v_norm = np.linalg.norm(v)\n",
    "    Wv_norm = np.linalg.norm(Wv, axis=1)\n",
    "\n",
    "    dot = np.dot(v, Wv.T)\n",
    "\n",
    "    cos_sim = dot / (v_norm * Wv_norm)\n",
    "\n",
    "    nns = np.flipud(np.argsort(cos_sim)[-k:])\n",
    "    ds = np.flipud(np.sort(cos_sim)[-k:])\n",
    "    \n",
    "    return [nns, ds]\n",
    "\n",
    "\n",
    "def show_nns(hands, word, k=10):\n",
    "    \"\"\"Helper function to print neighbors of a given word.\"\"\"\n",
    "    word = word.lower()\n",
    "    print(\"Nearest neighbors for '{:s}'\".format(word))\n",
    "    v = hands.get_vector(word)\n",
    "    for i, sim in zip(*find_nn_cos(v, hands.W, k)):\n",
    "        target_word = hands.vocab.id_to_word[i]\n",
    "        print(\"{:.03f} : '{:s}'\".format(sim, target_word))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors for 'diabetes'\n",
      "1.000 : 'diabetes'\n",
      "0.848 : 'hypertension'\n",
      "0.799 : 'obesity'\n",
      "0.780 : 'arthritis'\n",
      "0.779 : 'cancer'\n",
      "0.774 : 'alzheimer'\n",
      "0.765 : 'asthma'\n",
      "0.756 : 'cardiovascular'\n",
      "0.733 : 'disease'\n",
      "0.730 : 'epilepsy'\n",
      "\n",
      "Nearest neighbors for 'cancer'\n",
      "1.000 : 'cancer'\n",
      "0.821 : 'breast'\n",
      "0.807 : 'prostate'\n",
      "0.785 : 'disease'\n",
      "0.779 : 'diabetes'\n",
      "0.766 : 'cancers'\n",
      "0.751 : 'patients'\n",
      "0.749 : 'leukemia'\n",
      "0.744 : 'alzheimer'\n",
      "0.732 : 'lung'\n",
      "\n",
      "Nearest neighbors for 'depression'\n",
      "1.000 : 'depression'\n",
      "0.706 : 'illness'\n",
      "0.690 : 'anxiety'\n",
      "0.679 : 'severe'\n",
      "0.672 : 'onset'\n",
      "0.670 : 'schizophrenia'\n",
      "0.668 : 'disorder'\n",
      "0.666 : 'alcoholism'\n",
      "0.643 : 'psychosis'\n",
      "0.641 : 'mental'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_nns(hands, \"diabetes\")\n",
    "show_nns(hands, \"cancer\")\n",
    "show_nns(hands, \"depression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results we see make sense and showcase the capability of word embeddings. However, we do run into a few issues. For one, \n",
    "loading the file into our workspace requires careful memory management. This can become a problem when dealing with larger models or when we want to tweak our models and reload the data. Another issue is that we have to build our own help functions for performing calculations on the word vectors. Not inherently an issue, but these calculations are fairly standard and it is always a good idea to work smarter, not harder.\n",
    "\n",
    "As an alternative, we can look at third-party packages that offer fast and simple support for word vector operations. The package we will use for this project is Magnitude (https://github.com/plasticityai/magnitude). This package offers \"lazy-loading for faster cold starts in development, LRU memory caching for performance in production, multiple key queries, direct featurization to the inputs for a neural network, performant similiarity calculations, and other nice to have features for edge cases like handling out-of-vocabulary keys or misspelled keys and concatenating multiple vector models together.\" These are all great features that we can leverage for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Word Vectors - Magnitude\n",
    "\n",
    "Going through a few simple comparisons and exercises, we can see the difference between working with the raw text file versus working with the magnitude file:\n",
    "  - The zip file is ~4 times larger than the magnitude file. This is even more impressive consdering the text file still needs to be unpackaged.  \n",
    "  - Load times are extremely quick for the magnitude file, far outperforming the standard file.  \n",
    "  - Querying from the standard file outperforms the magnitude file, but querying from the magnitude file is simpler and offers additional functionality.  \n",
    "  \n",
    "While the increased query times is not ideal, especially when it comes to training, the portability and the increased functionality just makes life so much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Text File:\n",
      "\tFile Size:  862182613\n",
      "\tFile Load Time:  18.083816289901733\n",
      "\tQuery Time:  0.00012183189392089844\n",
      "\tHandling out-of-vocabulary words:\n",
      "\t\tWord not found in vocabulary\n",
      "\n",
      "Magnitude File:\n",
      "\tFile Size:  266366976\n",
      "\tFile Load Time:  0.002287149429321289\n",
      "\tQuery Time:  0.006619930267333984\n",
      "\tHandling out-of-vocabulary words:\n",
      "\t\t [-0.04397694  0.08708267  0.05870734 -0.04722567 -0.03879925  0.21312321\n",
      "  0.02859145 -0.03979973 -0.02670808  0.02556176 -0.07791763  0.0055145\n",
      " -0.03020298  0.06430179 -0.00551911  0.16249717 -0.06189246 -0.12206172\n",
      " -0.02767706 -0.05265569  0.13255737  0.02846519  0.0451067   0.11242716\n",
      "  0.01290785 -0.04876954 -0.04612697 -0.03764525 -0.00251381  0.11269477\n",
      "  0.11309229  0.09421328 -0.13763386 -0.02501031  0.01126506  0.06448203\n",
      "  0.06115726 -0.12342421  0.02004041 -0.0443186  -0.02901474 -0.01431345\n",
      "  0.05068584 -0.02549015 -0.08328359 -0.07138098  0.0835982  -0.03470181\n",
      " -0.00475797 -0.07226969  0.20147627 -0.02546141  0.16691468  0.15587942\n",
      " -0.10204505 -0.28276903 -0.04359986 -0.00812922  0.26467098 -0.01318733\n",
      "  0.04115933  0.2236795   0.06037727 -0.07199733  0.15238186  0.01320335\n",
      "  0.09773192  0.11063358 -0.01586969 -0.12897211 -0.0201993   0.07721622\n",
      "  0.11132904 -0.13067909 -0.00924318  0.07260409  0.05481729 -0.05902149\n",
      " -0.2339786  -0.02057123  0.01306966 -0.13869832 -0.08822653 -0.07845674\n",
      " -0.32157976 -0.10953958  0.09557799 -0.06474664 -0.03778845  0.03837843\n",
      " -0.01723297 -0.0244724  -0.07212664  0.06304205 -0.05542718  0.08676886\n",
      " -0.19776228 -0.12506526 -0.03333469  0.05330176]\n"
     ]
    }
   ],
   "source": [
    "print('Standard Text File:')\n",
    "print('\\tFile Size: ', os.stat('data/glove/glove.6B.zip').st_size)\n",
    "\n",
    "start = time.time()\n",
    "glove_vectors_txt = glove_helper.Hands(ndim=100, quiet=True)\n",
    "end = time.time()\n",
    "print('\\tFile Load Time: ', end - start)\n",
    "\n",
    "start = time.time()\n",
    "glove_vectors_txt.get_vector('diabetes')\n",
    "glove_vectors_txt.get_vector('cancer')\n",
    "glove_vectors_txt.get_vector('hypertension')\n",
    "end = time.time()\n",
    "print('\\tQuery Time: ', end - start)\n",
    "\n",
    "print('\\tHandling out-of-vocabulary words:')\n",
    "try:\n",
    "    print('\\t\\t', glove_vectors_txt.get_vector('wordnotfoundinvocab'))\n",
    "except AssertionError:\n",
    "    print('\\t\\tWord not found in vocabulary')\n",
    "\n",
    "print('\\nMagnitude File:')\n",
    "print('\\tFile Size: ', os.stat('data/glove-lemmatized.6B.100d.magnitude').st_size)\n",
    "\n",
    "start = time.time()\n",
    "glove_vectors_mag = Magnitude(\"data/glove-lemmatized.6B.100d.magnitude\")\n",
    "end = time.time()\n",
    "print('\\tFile Load Time: ', end - start)\n",
    "\n",
    "start = time.time()\n",
    "glove_vectors_mag.query(\"diabetes\")\n",
    "glove_vectors_mag.query(\"cancer\")\n",
    "glove_vectors_mag.query(\"hypertension\")\n",
    "end = time.time()\n",
    "print('\\tQuery Time: ', end - start)\n",
    "\n",
    "print('\\tHandling out-of-vocabulary words:')\n",
    "try:\n",
    "    print('\\t\\t', glove_vectors_mag.query('wordnotfoundinvocab'))\n",
    "except AssertionError:\n",
    "    print('\\t\\tWord not found in vocabulary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Selection - Biomedical Text\n",
    "\n",
    "-- Talk about importance of base corpora  \n",
    "-- Reference paper that compares medical coprora to general corpora  \n",
    "-- Show case actual examples by showing NN of GloVe vs medical  \n",
    "\n",
    "With a framework that allows more freedom in corpus selection, we can move into much more larger word embedding models. The GloVe model we have been previously working with is actually on the smaller side. Of course, a larger corpus offers more data to train on, thus better capturing word contexts and meanings. However, another determininig factor in corpus selection is the source of the text. In general, these pre-trained models are based on general topic sources such as Wikipedia and Gigaword. However, since we know the domain we are working in, it may make sense to pull from relevant text sources. \n",
    "\n",
    "A Comparison of Word Embeddings for the Biomedical Natural Language Processing (https://arxiv.org/pdf/1802.00400.pdf) explores this idea. The paper concluded that \"word embeddings trained on EHR and MedLit can capture the semantics of medical terms better and find semantically relevant medical terms closer to human expertsâ€™ judgments than those trained on GloVe and Google News.\" \n",
    "\n",
    "We can test these results ourselves by comparing GloVe against a biomedical based word embedding that was trained on text from PubMed and PubMed Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe length:  336951\n",
      "GloVe dimensions:  100\n",
      "\n",
      "Nearest Neighbor examples:\n",
      "10 NN for diabetes:\n",
      " [('diabetic', 0.7566893059521317), ('diabetis', 0.7465886369685321), ('obesity', 0.619293770727618), ('hypertension', 0.6162751523182464), ('cardiovascular', 0.5791516470463346), ('asthma', 0.5689611839459698), ('arthriti', 0.5554265183541941), ('mellitu', 0.5439654800171492), ('allergy', 0.5393456576654493), ('alzheimer', 0.5297674264739546)]\n",
      "10 NN for cancer:\n",
      " [('breast', 0.8210739), ('prostate', 0.8065967), ('disease', 0.78536785), ('diabetis', 0.7788438), ('patient', 0.75117147), ('leukemia', 0.7485109), ('alzheimer', 0.744444), ('lung', 0.73171055), ('diseasis', 0.729254), ('heart', 0.7241202)]\n",
      "10 NN for hyperlipidemia:\n",
      " [('dyslipidemia', 0.6900931), ('hypercholesterolemia', 0.67991346), ('insulin-dependent', 0.6547221), ('insipidu', 0.61982), ('hyperglycemia', 0.6196113), ('vaginismu', 0.61709344), ('metformin', 0.6067523), ('pre-eclampsia', 0.60390294), ('prediabetis', 0.6029445), ('polymyositi', 0.60282224)]\n",
      "10 NN for e119:\n",
      " [('e19', 0.9162408356535976), ('phahon', 0.5892266446423353), ('werken', 0.5879736771166904), ('transsiberian', 0.5842905062903658), ('brookton', 0.5811409758690093), ('maai', 0.5788427014310997), ('surinaamse', 0.57560142232758), ('e22', 0.5739006580512447), ('50-2', 0.5728058762028345), ('bagaduce', 0.5709029514547086)]\n"
     ]
    }
   ],
   "source": [
    "print('GloVe length: ', len(glove_vectors_mag))\n",
    "print('GloVe dimensions: ', glove_vectors_mag.dim)\n",
    "\n",
    "print('\\nNearest Neighbor examples:')\n",
    "print('10 NN for diabetes:\\n', glove_vectors_mag.most_similar(\"diabetes\", topn = 10))\n",
    "print('10 NN for cancer:\\n', glove_vectors_mag.most_similar(\"cancer\", topn = 10))\n",
    "print('10 NN for hyperlipidemia:\\n', glove_vectors_mag.most_similar(\"hyperlipidemia\", topn = 10))\n",
    "print('10 NN for e119:\\n', glove_vectors_mag.most_similar(\"e119\", topn = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical length:  5443656\n",
      "Medical dimensions:  200\n"
     ]
    }
   ],
   "source": [
    "med_vectors = Magnitude(\"data/wikipedia-pubmed-and-PMC-w2v.magnitude\", pad_to_length=30)\n",
    "print('Medical length: ', len(med_vectors))\n",
    "print('Medical dimensions: ', med_vectors.dim)\n",
    "\n",
    "# print('\\nNearest Neighbor examples:')\n",
    "# print('10 NN for diabetes:\\n', med_vectors.most_similar(\"diabetes\", topn = 10))\n",
    "# print('10 NN for cancer:\\n', med_vectors.most_similar(\"cancer\", topn = 10))\n",
    "# print('10 NN for hyperlipidemia:\\n', med_vectors.most_similar(\"hyperlipidemia\", topn = 10))\n",
    "# print('10 NN for e119:\\n', med_vectors.most_similar(\"e119\", topn = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data - Labeled Electronic Health Record Text\n",
    "\n",
    "-- Refer back to goal of project  \n",
    "-- Talk about difficulty of getting medical data (HIPPA)  \n",
    "-- Reference MTsamples as source of data  \n",
    "-- Show raw data unprocessed  \n",
    "-- Briefly talk about transformations  \n",
    "\n",
    "The goal of this project is to classify Eletronic Health Record (EHR) text. This of course means that we need to get our hands on some EHR data. This can be particularly difficult due to the strict rules and guidelines around healthcare data. The Health Insurance Portability and Accountability Act of 1996, or HIPAA, outlines a set of rules that help protect the privacy of our health information. These rules are vital for building a healthcare system where we can trust our healthcare providers and caregivers, so it is important that we adhere to the standards set by HIPAA. \n",
    "\n",
    "For this project, we will be using a dataset provided by MTSamples.com. They provide ~5,000 transcribed medical reports covering 40 specialty types. All of the notes have been de-identified of protected health information, making them HIPAA compliant. Below we will explore a few rows of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EHR Sentence Example:\n",
      "\n",
      "['Bariatrics', 'PAST MEDICAL HISTORY:, He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, and lifting objects off the floor.  He exercises three times a week at home and does cardio.  He has difficulty walking two blocks or five flights of stairs.  Difficulty with snoring.  He has muscle and joint pains including knee pain, back pain, foot and ankle pain, and swelling.  He has gastroesophageal reflux disease.,PAST SURGICAL HISTORY:, Includes reconstructive surgery on his right hand 13 years ago.  ,SOCIAL HISTORY:, He is currently single.  He has about ten drinks a year.  He had smoked significantly up until several months ago.  He now smokes less than three cigarettes a day.,FAMILY HISTORY:, Heart disease in both grandfathers, grandmother with stroke, and a grandmother with diabetes.  Denies obesity and hypertension in other family members.,CURRENT MEDICATIONS:, None.,ALLERGIES:,  He is allergic to Penicillin.,MISCELLANEOUS/EATING HISTORY:, He has been going to support groups for seven months with Lynn Holmberg in Greenwich and he is from Eastchester, New York and he feels that we are the appropriate program.  He had a poor experience with the Greenwich program.  Eating history, he is not an emotional eater.  Does not like sweets.  He likes big portions and carbohydrates.  He likes chicken and not steak.  He currently weighs 312 pounds.  Ideal body weight would be 170 pounds.  He is 142 pounds overweight.  If ,he lost 60% of his excess body weight that would be 84 pounds and he should weigh about 228.,REVIEW OF SYSTEMS: ,Negative for head, neck, heart, lungs, GI, GU, orthopedic, and skin.  Specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, CVA, venous insufficiency, thrombophlebitis, asthma, shortness of breath, COPD, emphysema, sleep apnea, diabetes, leg and foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  Denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:, He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Afebrile.  Vital Signs are stable.']\n",
      "['Bariatrics', 'HISTORY OF PRESENT ILLNESS: , I have seen ABC today.  He is a very pleasant gentleman who is 42 years old, 344 pounds.  He is 5\\'9\"\"\"\".  He has a BMI of 51.  He has been overweight for ten years since the age of 33, at his highest he was 358 pounds, at his lowest 260.  He is pursuing surgical attempts of weight loss to feel good, get healthy, and begin to exercise again.  He wants to be able to exercise and play volleyball.  Physically, he is sluggish.  He gets tired quickly.  He does not go out often.  When he loses weight he always regains it and he gains back more than he lost.  His biggest weight loss is 25 pounds and it was three months before he gained it back.  He did six months of not drinking alcohol and not taking in many calories.  He has been on multiple commercial weight loss programs including Slim Fast for one month one year ago and Atkin\\'s Diet for one month two years ago.,PAST MEDICAL HISTORY: , He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, difficulty walking, high cholesterol, and high blood pressure.  He has asthma and difficulty walking two blocks or going eight to ten steps.  He has sleep apnea and snoring.  He is a diabetic, on medication.  He has joint pain, knee pain, back pain, foot and ankle pain, leg and foot swelling.  He has hemorrhoids.,PAST SURGICAL HISTORY: , Includes orthopedic or knee surgery.,SOCIAL HISTORY: , He is currently single.  He drinks alcohol ten to twelve drinks a week, but does not drink five days a week and then will binge drink.  He smokes one and a half pack a day for 15 years, but he has recently stopped smoking for the past two weeks.,FAMILY HISTORY: , Obesity, heart disease, and diabetes.  Family history is negative for hypertension and stroke.,CURRENT MEDICATIONS:,  Include Diovan, Crestor, and Tricor.,MISCELLANEOUS/EATING HISTORY:  ,He says a couple of friends of his have had heart attacks and have had died.  He used to drink everyday, but stopped two years ago.  He now only drinks on weekends.  He is on his second week of Chantix, which is a medication to come off smoking completely.  Eating, he eats bad food.  He is single.  He eats things like bacon, eggs, and cheese, cheeseburgers, fast food, eats four times a day, seven in the morning, at noon, 9 p.m., and 2 a.m.  He currently weighs 344 pounds and 5\\'9\"\"\"\".  His ideal body weight is 160 pounds.  He is 184 pounds overweight.  If he lost 70% of his excess body weight that would be 129 pounds and that would get him down to 215.,REVIEW OF SYSTEMS: , Negative for head, neck, heart, lungs, GI, GU, orthopedic, or skin.  He also is positive for gout.  He denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, pulmonary embolism, or CVA.  He denies venous insufficiency or thrombophlebitis.  Denies shortness of breath, COPD, or emphysema.  Denies thyroid problems, hip pain, osteoarthritis, rheumatoid arthritis, GERD, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  He denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:  ,He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Neck is soft and supple.  Lungs:  He has positive wheezing bilaterally.  Heart is regular rhythm and rate.  His abdomen is soft.  Extremities:  He has 1+ pitting edema.,IMPRESSION/PLAN:,  I have explained to him the risks and potential complications of laparoscopic gastric bypass in detail and these include bleeding, infection, deep venous thrombosis, pulmonary embolism, leakage from the gastrojejuno-anastomosis, jejunojejuno-anastomosis, and possible bowel obstruction among other potential complications.  He understands.  He wants to proceed with workup and evaluation for laparoscopic Roux-en-Y gastric bypass.  He will need to get a letter of approval from Dr. XYZ.  He will need to see a nutritionist and mental health worker.  He will need an upper endoscopy by either Dr. XYZ.  He will need to go to Dr. XYZ as he previously had a sleep study.  We will need another sleep study.  He will need H. pylori testing, thyroid function tests, LFTs, glycosylated hemoglobin, and fasting blood sugar.  After this is performed, we will submit him for insurance approval.']\n"
     ]
    }
   ],
   "source": [
    "ehr_notes = []\n",
    "with open('data/ehr_samples.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        ehr_notes.append([row['Specialty'], row['Note']])\n",
    "        \n",
    "print('EHR Sentence Example:\\n')\n",
    "print(ehr_notes[0])\n",
    "print(ehr_notes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing - Pre-Processing the EHR Notes\n",
    "\n",
    "-- Talk about how we need to manage our scope. Mention how ML on larger text scales  \n",
    "-- For simplicity, going to limit ourselves to sentences. Possibly moving on to more text if we see promising results  \n",
    "-- Talk about the standard set of NLTK functions  \n",
    "-- Show a new sentence  \n",
    "\n",
    "With the EHR data now loaded, we could technically start applying Machine Learning operations as is. However, as with a lot of text-based data, there are a few characteristics that are less than ideal for this project. The first obstacle is managing our text length. As our input text grows, so does the number of variables and the number of operations. Depending on our algorithm, these values can scale exponentially, causing runtime and resource usage to explode out of hand. To help manage the scope of our input text, we will be breaking up our notes into sentences. This should give us enough context to learn the more complex relationships between our words while minimizing runtime. Of course, if we find that runtime performance is not an issue, we can try further expanding our input text.\n",
    "\n",
    "Another pre-processing step we can take is to apply basic natural language cleanup techniques that standardize the text and remove non-essential information. Thankfully, python has a package called the Natural Language Toolkit (NLTK) that provides a lot of these transformations as built-in functions. The operations we will use for this project are converting all text to lowercase, removing punctation, filtering out stop words, and removing blanks.\n",
    "\n",
    "After all of the pre-processing, we can take a look at what the EHR notes now look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_sentences = []\n",
    "for record in ehr_notes:\n",
    "    sent_text = nltk.sent_tokenize(record[1])\n",
    "    for sent in sent_text:\n",
    "        tokens = word_tokenize(sent)\n",
    "\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "        # filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "#         # stem words\n",
    "#         porter = PorterStemmer()\n",
    "#         tokens = [porter.stem(word) for word in tokens]\n",
    "\n",
    "        # remove blanks\n",
    "        tokens = [w for w in tokens if w != '']\n",
    "\n",
    "        ehr_sentences.append([record[0], ' '.join(tokens)])\n",
    "\n",
    "random.Random(4).shuffle(ehr_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Psychiatry', 'exhusband died 1980 acute pancreatitis secondary alcohol abuse'], ['Gynecology', 'patient taken post anesthesia care unit stable condition'], ['Consult', 'send pertussis pcr'], ['Discharge', 'admission diagnoses 1'], ['Surgery', 'time removed 12 mm broach proceeded implanting polyethylene liner within acetabulum'], ['General', 'peripheral vascular disease status post recent last week pta right lower extremity social history negative smoking drinking current home medications novolog 20 units meal lantus 30 units bedtime crestor 10 mg daily micardis 80 mg daily imdur 30 mg daily amlodipine 10 mg daily coreg 125 mg bid lasix 20 mg daily ecotrin 325 mg daily calcitriol 05 mcg daily review systems patient denies complaints states right hand left foot swollen painful came emergency room'], ['Surgery', 'estimated blood loss less 15 ml'], ['Surgery', 'base tumor fulgurated periphery normal mucosa surrounding base bladder tumor'], ['Cardiovascular', 'focal areas consolidation suggest pneumonia'], ['Surgery', 'enterogastritis procedure performed egd peg tube placement using russell technique anesthesia iv sedation 1 lidocaine local estimated blood loss none complications none brief history 44yearold africanamerican female well known service']]\n"
     ]
    }
   ],
   "source": [
    "print(ehr_sentences[:10])\n",
    "\n",
    "specialties = ['Allergy', 'Autopsy', 'Bariatrics', 'Cardiovascular', 'Chart', 'Chiropractic', 'Consult'\n",
    "               , 'Cosmetic', 'Dentistry', 'Dermatology', 'Diet', 'Discharge', 'Emergency', 'Endocrinology'\n",
    "               , 'Gastroenterology', 'General', 'Gynecology', 'Hospice', 'IME', 'Letters', 'Nephrology', 'Neurology'\n",
    "               , 'Neurosurgery', 'Office Notes', 'Oncology', 'Ophthalmology', 'Orthopedic', 'Otolaryngology'\n",
    "               , 'Pain Management', 'Pathology', 'Pediatrics', 'Podiatry', 'Psychiatry', 'Radiology', 'Rehab'\n",
    "               , 'Rheumatology', 'Sleep', 'Speech', 'Surgery', 'Urology']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS AND APPROACHES\n",
    "## Naive Nearest Neighbor\n",
    "\n",
    "-- Talk about distance vs similarity  \n",
    "-- Talk about fundametal co-occurence principle of word to vector  \n",
    "-- How those vectors repsenet context or meaning  \n",
    "-- If a sentence is more similar to our category, we can simply label it as such  \n",
    "-- SHow some good examples but emphasize the bad examples  \n",
    "\n",
    "\n",
    "The first method we will explore will be to just leverage the word embedding space with no Machine Learning at all. We mentioned earlier that the word vectors capture context and meaning. Additionally position of these vectors in relation to eachother also convey word relationships. At the core of it, vectors clustered together are more similar in context and meaning. Using this principle, we can use our categories as anchors in our word embedding, calculate a similarity score for a sentence, and identify which category is the nearest neighbor to our sentence. \n",
    "\n",
    "This is a very naive approach but it will be a good exercise and can at least set a baseline for performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between diabetes and mellitus:  0.80347604\n",
      "Similarity between diabetes and breast:  0.26328182\n",
      "\n",
      "Similarity between cancer and mellitus:  0.13384798\n",
      "Similarity between cancer and breast:  0.7488326\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between diabetes and mellitus: ', med_vectors.similarity(\"diabetes\", \"mellitus\"))\n",
    "print('Similarity between diabetes and breast: ', med_vectors.similarity(\"diabetes\", \"breast\"))\n",
    "\n",
    "print('\\nSimilarity between cancer and mellitus: ', med_vectors.similarity(\"cancer\", \"mellitus\"))\n",
    "print('Similarity between cancer and breast: ', med_vectors.similarity(\"cancer\", \"breast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Correct Classifications:  98\n",
      "Accuracy:  0.049\n"
     ]
    }
   ],
   "source": [
    "nn_results = []\n",
    "for i, ehr_sent in enumerate(ehr_sentences[0:2000]):\n",
    "#     print(ehr_sent)\n",
    "    \n",
    "    most_similar_specialty = []\n",
    "    \n",
    "    for specialty in specialties:\n",
    "        spec_similarity_sum = 0\n",
    "        for token in ehr_sent[1].split(' '):\n",
    "#             print('\\t', token, med_vectors.similarity(specialty, token))\n",
    "            \n",
    "            spec_similarity_sum += med_vectors.similarity(specialty, token)\n",
    "        \n",
    "        spec_similarity = spec_similarity_sum / len(ehr_sent[1].split(' '))\n",
    "        \n",
    "#         print(specialty, spec_similarity)\n",
    "\n",
    "        if not most_similar_specialty:\n",
    "            most_similar_specialty = [i, ehr_sent[0], specialty, spec_similarity]\n",
    "        elif spec_similarity > most_similar_specialty[3]:\n",
    "            most_similar_specialty = [i, ehr_sent[0], specialty, spec_similarity]\n",
    "        \n",
    "    nn_results.append(most_similar_specialty)\n",
    "\n",
    "    \n",
    "correct_results = [result for result in nn_results if result[1] == result[2]]\n",
    "print('# of Correct Classifications: ', len(correct_results))\n",
    "print('Accuracy: ', len(correct_results) / len(nn_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of correct classification:\n",
      "\tSentence:  ['Orthopedic', 'exposed vertebral bodies c2c3 c4c5 bridged plate']\n",
      "\n",
      "\tTrue category: Orthopedic\n",
      "\tPredicted category: Orthopedic\n",
      "\n",
      "\tSimilarities:\n",
      "\t\t exposed -0.03660483\n",
      "\t\t vertebral 0.266623\n",
      "\t\t bodies 0.068785824\n",
      "\t\t c2c3 0.031137193347711197\n",
      "\t\t c4c5 0.09221873311276046\n",
      "\t\t bridged 0.057441555\n",
      "\t\t plate 0.039083302\n",
      "\t\tAverage similarity:  0.1750587690063761\n"
     ]
    }
   ],
   "source": [
    "print('Example of correct classification:')\n",
    "\n",
    "correct_example = correct_results[0]\n",
    "example_sentence = ehr_sentences[correct_example[0]]\n",
    "print('\\tSentence: ', example_sentence)\n",
    "\n",
    "print('\\n\\tTrue category:', correct_example[1])\n",
    "print('\\tPredicted category:', correct_example[2])\n",
    "\n",
    "print('\\n\\tTrue/Predicted Similarities:')\n",
    "for token in example_sentence[1].split(' '):\n",
    "    print('\\t\\t', token, med_vectors.similarity(correct_example[1], token))\n",
    "    spec_similarity_sum += med_vectors.similarity(correct_example[1], token)\n",
    "\n",
    "spec_similarity = spec_similarity_sum / len(example_sentence.split(' '))\n",
    "print('\\t\\tAverage similarity: ', spec_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of incorrect classification:\n",
      "\tSentence:  ['Neurology', 'see velocity measurements left carotid eca measurement 0938 msecond']\n",
      "\n",
      "\tTrue category: Neurology\n",
      "\tPredicted category: Endocrinology\n",
      "\n",
      "\tTrue Similarities:\n",
      "\t\t see 0.034260437\n",
      "\t\t velocity 0.07255719\n",
      "\t\t measurements 0.015290075\n",
      "\t\t left 0.07127067\n",
      "\t\t carotid 0.07629804\n",
      "\t\t eca 0.094461195\n",
      "\t\t measurement -0.020491015\n",
      "\t\t 0938 0.10253124\n",
      "\t\t msecond 0.030581191\n",
      "\t\tAverage similarity:  0.48662400427592156\n",
      "\n",
      "\tPredicted Similarities:\n",
      "\t\t see -0.006658733\n",
      "\t\t velocity 0.05569666\n",
      "\t\t measurements 0.05710432\n",
      "\t\t left 0.05892444\n",
      "\t\t carotid 0.04782131\n",
      "\t\t eca 0.15068905\n",
      "\t\t measurement 0.05482881\n",
      "\t\t 0938 0.14380054\n",
      "\t\t msecond 0.061377887\n",
      "\t\tAverage similarity:  0.5559111470957501\n"
     ]
    }
   ],
   "source": [
    "print('Example of incorrect classification:')\n",
    "\n",
    "incorrect_example = nn_results[0]\n",
    "example_sentence = ehr_sentences[incorrect_example[0]]\n",
    "print('\\tSentence: ', example_sentence)\n",
    "\n",
    "print('\\n\\tTrue category:', incorrect_example[1])\n",
    "print('\\tPredicted category:', incorrect_example[2])\n",
    "\n",
    "print('\\n\\tTrue Similarities:')\n",
    "for token in example_sentence[1].split(' '):\n",
    "    print('\\t\\t', token, med_vectors.similarity(incorrect_example[1], token))\n",
    "    spec_similarity_sum += med_vectors.similarity(incorrect_example[1], token)\n",
    "\n",
    "spec_similarity = spec_similarity_sum / len(example_sentence[1].split(' '))\n",
    "print('\\t\\tAverage similarity: ', spec_similarity)\n",
    "\n",
    "print('\\n\\tPredicted Similarities:')\n",
    "for token in example_sentence[1].split(' '):\n",
    "    print('\\t\\t', token, med_vectors.similarity(incorrect_example[2], token))\n",
    "    spec_similarity_sum += med_vectors.similarity(incorrect_example[2], token)\n",
    "\n",
    "spec_similarity = spec_similarity_sum / len(example_sentence[1].split(' '))\n",
    "print('\\t\\tAverage similarity: ', spec_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see, the results are pretty terrible with an accuracy of 5%. Looking at an example the classifier got right, it relied on words that are exclusively and very distinctly related. However, these strong signals are not always present in our sentences. Looking at an incorrect example, we see how the signals are being drowned out or offset by the other words. This emphasizes the need for some type of model that can learn and weigh the words that provide strong signals for particular categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS AND APPROACHES\n",
    "## Neural Networks\n",
    "\n",
    "A neural network will allow us to build a model that can take in the word vectors as inputs and learn the complex relationships between those vectors to better classify the target sentence. This is a more holistic approach that tries to capture meaning from the entire sentence rather than token by token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Training and Test Data\n",
    "\n",
    "Before we can start building our neural networks, we first have to define our datasets. Specifically, we have to break up our EHR data so that we have records that we can train on and records that are exclusively used to test on. Maintaining a separate set for testing ensures we avoid overfitting our data.\n",
    "\n",
    "We will use some built-in functions provided by Magnitude that helps encode our classes/categories. We then partition our data into our train and test sets. For each set we have both data and labels. Initially, we will be making these partitions small to make iterating through model development much quicker. However, once the models are developed, we will expand our datasets to include all of our data. To ensure we defined our data correctly, we can print a few lines from the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psychiatry\n",
      "First line of train/test data:\n",
      "\t ['exhusband', 'died', '1980', 'acute', 'pancreatitis', 'secondary', 'alcohol', 'abuse']\n",
      "\t 0 Psychiatry\n",
      "\t ['cystoscopy', 'revealed', 'good', 'efflux', 'urine', 'ureteral', 'openings']\n",
      "\t 4 Surgery\n",
      "Second line of train/test data:\n",
      "\t ['patient', 'taken', 'post', 'anesthesia', 'care', 'unit', 'stable', 'condition']\n",
      "\t 1 Gynecology\n",
      "\t ['help', 'anyway', 'improve', 'patient', 'laboratory', 'abnormalities']\n",
      "\t 5 General\n"
     ]
    }
   ],
   "source": [
    "add_intent, intent_to_int, int_to_intent = MagnitudeUtils.class_encoding()\n",
    "\n",
    "x_train = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[:130000]]\n",
    "x_test = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[130001:]]\n",
    "\n",
    "y_train = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[:130000]]\n",
    "y_test = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[130001:]]\n",
    "\n",
    "y_train = list(np.array(y_train).reshape(len(y_train)))\n",
    "y_test = list(np.array(y_test).reshape(len(y_test)))\n",
    "\n",
    "num_training = len(x_train)\n",
    "num_test = len(x_test)\n",
    "num_outputs = int(max(max(y_train), max(y_test))) + 1\n",
    "\n",
    "print(int_to_intent(0))\n",
    "\n",
    "print(\"First line of train/test data:\")\n",
    "print(\"\\t\", x_train[0])\n",
    "print(\"\\t\", y_train[0], int_to_intent(y_train[0]))\n",
    "print(\"\\t\", x_test[0])\n",
    "print(\"\\t\", y_test[0], int_to_intent(y_test[0]))\n",
    "print(\"Second line of train/test data:\")\n",
    "print(\"\\t\", x_train[1])\n",
    "print(\"\\t\", y_train[1], int_to_intent(y_train[1]))\n",
    "print(\"\\t\", x_test[1])\n",
    "print(\"\\t\", y_test[1], int_to_intent(y_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convultional Neural Network\n",
    "-- Explain conv layers, focusing on 1d  \n",
    "-- how it learns the best filters  \n",
    "-- talk about exact model structure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_2 (GaussianNo (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 30, 128)           179328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 15, 128)           114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 40)                2600      \n",
      "=================================================================\n",
      "Total params: 305,000\n",
      "Trainable params: 305,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS = 30 # The maximum number of words the sequence model will consider\n",
    "STD_DEV = 0.01 # Deviation of noise for Gaussian Noise applied to the embeddings\n",
    "DROPOUT_RATIO = .5 # The ratio to dropout\n",
    "BATCH_SIZE = 100 # The number of examples per train/validation step\n",
    "EPOCHS = 100 # The number of times to repeat through all of the training data\n",
    "LEARNING_RATE = .01 # The learning rate for the optimizer\n",
    "NUM_FILTERS = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(STD_DEV, input_shape=(MAX_WORDS, med_vectors.dim)))\n",
    "model.add(Conv1D(NUM_FILTERS, 7, activation='relu', padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(NUM_FILTERS, 7, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(DROPOUT_RATIO))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1300/1300 [==============================] - 386s 297ms/step - loss: 2.2858 - categorical_accuracy: 0.3297 - val_loss: 2.2034 - val_categorical_accuracy: 0.3286\n",
      "Epoch 3/100\n",
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.8635 - categorical_accuracy: 0.3625 - val_loss: 2.1064 - val_categorical_accuracy: 0.3178\n",
      "Epoch 9/100\n",
      "1300/1300 [==============================] - 385s 296ms/step - loss: 1.8293 - categorical_accuracy: 0.3664 - val_loss: 2.1046 - val_categorical_accuracy: 0.3126\n",
      "Epoch 10/100\n",
      "1300/1300 [==============================] - 385s 296ms/step - loss: 1.8023 - categorical_accuracy: 0.3686 - val_loss: 2.1088 - val_categorical_accuracy: 0.3160\n",
      "Epoch 11/100\n",
      "1300/1300 [==============================] - 397s 305ms/step - loss: 1.7805 - categorical_accuracy: 0.3705 - val_loss: 2.1148 - val_categorical_accuracy: 0.3131\n",
      "Epoch 12/100\n",
      "1300/1300 [==============================] - 400s 308ms/step - loss: 1.7549 - categorical_accuracy: 0.3718 - val_loss: 2.1337 - val_categorical_accuracy: 0.3059\n",
      "Epoch 13/100\n",
      " 280/1300 [=====>........................] - ETA: 4:42 - loss: 1.7451 - categorical_accuracy: 0.3724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 383s 294ms/step - loss: 1.6911 - categorical_accuracy: 0.3789 - val_loss: 2.1788 - val_categorical_accuracy: 0.2978\n",
      "Epoch 17/100\n",
      "1300/1300 [==============================] - 388s 299ms/step - loss: 1.6788 - categorical_accuracy: 0.3797 - val_loss: 2.1856 - val_categorical_accuracy: 0.2977\n",
      "Epoch 18/100\n",
      "1078/1300 [=======================>......] - ETA: 58s - loss: 1.6659 - categorical_accuracy: 0.3805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 385s 296ms/step - loss: 1.6251 - categorical_accuracy: 0.3847 - val_loss: 2.2731 - val_categorical_accuracy: 0.2962\n",
      "Epoch 23/100\n",
      "1300/1300 [==============================] - 388s 298ms/step - loss: 1.6148 - categorical_accuracy: 0.3857 - val_loss: 2.2734 - val_categorical_accuracy: 0.2924\n",
      "Epoch 24/100\n",
      " 926/1300 [====================>.........] - ETA: 1:38 - loss: 1.6125 - categorical_accuracy: 0.3866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 385s 296ms/step - loss: 1.5792 - categorical_accuracy: 0.3913 - val_loss: 2.2866 - val_categorical_accuracy: 0.2858\n",
      "Epoch 29/100\n",
      "1300/1300 [==============================] - 387s 298ms/step - loss: 1.5722 - categorical_accuracy: 0.3913 - val_loss: 2.2968 - val_categorical_accuracy: 0.2847\n",
      "Epoch 30/100\n",
      " 841/1300 [==================>...........] - ETA: 2:01 - loss: 1.5685 - categorical_accuracy: 0.3933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 389s 299ms/step - loss: 1.5611 - categorical_accuracy: 0.3924 - val_loss: 2.3101 - val_categorical_accuracy: 0.2778\n",
      "Epoch 32/100\n",
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.5564 - categorical_accuracy: 0.3941 - val_loss: 2.3275 - val_categorical_accuracy: 0.2804\n",
      "Epoch 33/100\n",
      "1300/1300 [==============================] - 386s 297ms/step - loss: 1.5504 - categorical_accuracy: 0.3960 - val_loss: 2.3099 - val_categorical_accuracy: 0.2783\n",
      "Epoch 34/100\n",
      "1300/1300 [==============================] - 383s 294ms/step - loss: 1.5460 - categorical_accuracy: 0.3951 - val_loss: 2.3147 - val_categorical_accuracy: 0.2783\n",
      "Epoch 35/100\n",
      " 403/1300 [========>.....................] - ETA: 3:58 - loss: 1.5440 - categorical_accuracy: 0.3898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.5248 - categorical_accuracy: 0.3977 - val_loss: 2.3545 - val_categorical_accuracy: 0.2746\n",
      "Epoch 39/100\n",
      "1300/1300 [==============================] - 396s 304ms/step - loss: 1.5246 - categorical_accuracy: 0.3974 - val_loss: 2.3392 - val_categorical_accuracy: 0.2782\n",
      "Epoch 40/100\n",
      "1136/1300 [=========================>....] - ETA: 43s - loss: 1.5222 - categorical_accuracy: 0.3978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 401s 309ms/step - loss: 1.5065 - categorical_accuracy: 0.3988 - val_loss: 2.3636 - val_categorical_accuracy: 0.2778\n",
      "Epoch 45/100\n",
      "1300/1300 [==============================] - 387s 298ms/step - loss: 1.4993 - categorical_accuracy: 0.3987 - val_loss: 2.3910 - val_categorical_accuracy: 0.2710\n",
      "Epoch 46/100\n",
      "1023/1300 [======================>.......] - ETA: 1:12 - loss: 1.5012 - categorical_accuracy: 0.3995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 387s 298ms/step - loss: 1.4851 - categorical_accuracy: 0.4018 - val_loss: 2.3821 - val_categorical_accuracy: 0.2711\n",
      "Epoch 51/100\n",
      "1300/1300 [==============================] - 385s 296ms/step - loss: 1.4830 - categorical_accuracy: 0.4026 - val_loss: 2.3930 - val_categorical_accuracy: 0.2689\n",
      "Epoch 52/100\n",
      "1300/1300 [==============================] - 387s 297ms/step - loss: 1.4774 - categorical_accuracy: 0.4039 - val_loss: 2.4131 - val_categorical_accuracy: 0.2713\n",
      "Epoch 53/100\n",
      "1300/1300 [==============================] - 389s 299ms/step - loss: 1.4783 - categorical_accuracy: 0.4011 - val_loss: 2.4158 - val_categorical_accuracy: 0.2664\n",
      "Epoch 54/100\n",
      "1300/1300 [==============================] - 390s 300ms/step - loss: 1.4739 - categorical_accuracy: 0.4034 - val_loss: 2.4228 - val_categorical_accuracy: 0.2673\n",
      "Epoch 55/100\n",
      " 816/1300 [=================>............] - ETA: 2:09 - loss: 1.4743 - categorical_accuracy: 0.4049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.4611 - categorical_accuracy: 0.4034 - val_loss: 2.4133 - val_categorical_accuracy: 0.2691\n",
      "Epoch 60/100\n",
      "1300/1300 [==============================] - 390s 300ms/step - loss: 1.4581 - categorical_accuracy: 0.4065 - val_loss: 2.4581 - val_categorical_accuracy: 0.2612\n",
      "Epoch 61/100\n",
      " 687/1300 [==============>...............] - ETA: 2:43 - loss: 1.4571 - categorical_accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 388s 298ms/step - loss: 1.4463 - categorical_accuracy: 0.4069 - val_loss: 2.4897 - val_categorical_accuracy: 0.2686\n",
      "Epoch 66/100\n",
      "1300/1300 [==============================] - 388s 299ms/step - loss: 1.4459 - categorical_accuracy: 0.4072 - val_loss: 2.4618 - val_categorical_accuracy: 0.2623\n",
      "Epoch 67/100\n",
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.4420 - categorical_accuracy: 0.4086 - val_loss: 2.4780 - val_categorical_accuracy: 0.2629\n",
      "Epoch 68/100\n",
      "1300/1300 [==============================] - 389s 299ms/step - loss: 1.4411 - categorical_accuracy: 0.4081 - val_loss: 2.4873 - val_categorical_accuracy: 0.2639\n",
      "Epoch 69/100\n",
      "1300/1300 [==============================] - 386s 297ms/step - loss: 1.4390 - categorical_accuracy: 0.4079 - val_loss: 2.4892 - val_categorical_accuracy: 0.2611\n",
      "Epoch 70/100\n",
      "1300/1300 [==============================] - 388s 298ms/step - loss: 1.4379 - categorical_accuracy: 0.4084 - val_loss: 2.4886 - val_categorical_accuracy: 0.2610\n",
      "Epoch 71/100\n",
      "1300/1300 [==============================] - 392s 301ms/step - loss: 1.4348 - categorical_accuracy: 0.4083 - val_loss: 2.4933 - val_categorical_accuracy: 0.2661\n",
      "Epoch 72/100\n",
      "1300/1300 [==============================] - 389s 299ms/step - loss: 1.4318 - categorical_accuracy: 0.4079 - val_loss: 2.5014 - val_categorical_accuracy: 0.2581\n",
      "Epoch 73/100\n",
      "1300/1300 [==============================] - 391s 301ms/step - loss: 1.4305 - categorical_accuracy: 0.4082 - val_loss: 2.5117 - val_categorical_accuracy: 0.2616\n",
      "Epoch 74/100\n",
      "1300/1300 [==============================] - 388s 299ms/step - loss: 1.4334 - categorical_accuracy: 0.4075 - val_loss: 2.5061 - val_categorical_accuracy: 0.2628\n",
      "Epoch 75/100\n",
      "1300/1300 [==============================] - 456s 351ms/step - loss: 1.4245 - categorical_accuracy: 0.4086 - val_loss: 2.4979 - val_categorical_accuracy: 0.2631\n",
      "Epoch 76/100\n",
      "1300/1300 [==============================] - 560s 431ms/step - loss: 1.4254 - categorical_accuracy: 0.4079 - val_loss: 2.5090 - val_categorical_accuracy: 0.2623\n",
      "Epoch 77/100\n",
      "1300/1300 [==============================] - 557s 428ms/step - loss: 1.4234 - categorical_accuracy: 0.4110 - val_loss: 2.5151 - val_categorical_accuracy: 0.2642\n",
      "Epoch 78/100\n",
      "1300/1300 [==============================] - 565s 434ms/step - loss: 1.4208 - categorical_accuracy: 0.4098 - val_loss: 2.4975 - val_categorical_accuracy: 0.2610\n",
      "Epoch 79/100\n",
      "1300/1300 [==============================] - 575s 442ms/step - loss: 1.4208 - categorical_accuracy: 0.4105 - val_loss: 2.5239 - val_categorical_accuracy: 0.2563\n",
      "Epoch 80/100\n",
      "1300/1300 [==============================] - 575s 443ms/step - loss: 1.4196 - categorical_accuracy: 0.4110 - val_loss: 2.5087 - val_categorical_accuracy: 0.2617\n",
      "Epoch 81/100\n",
      "1300/1300 [==============================] - 576s 443ms/step - loss: 1.4169 - categorical_accuracy: 0.4117 - val_loss: 2.5183 - val_categorical_accuracy: 0.2593\n",
      "Epoch 82/100\n",
      "1300/1300 [==============================] - 457s 352ms/step - loss: 1.4128 - categorical_accuracy: 0.4135 - val_loss: 2.5132 - val_categorical_accuracy: 0.2527\n",
      "Epoch 83/100\n",
      "1300/1300 [==============================] - 408s 314ms/step - loss: 1.4109 - categorical_accuracy: 0.4134 - val_loss: 2.5430 - val_categorical_accuracy: 0.2587\n",
      "Epoch 84/100\n",
      "1300/1300 [==============================] - 401s 309ms/step - loss: 1.4099 - categorical_accuracy: 0.4118 - val_loss: 2.5204 - val_categorical_accuracy: 0.2603\n",
      "Epoch 85/100\n",
      "1300/1300 [==============================] - 397s 305ms/step - loss: 1.4096 - categorical_accuracy: 0.4120 - val_loss: 2.5678 - val_categorical_accuracy: 0.2559\n",
      "Epoch 86/100\n",
      "1300/1300 [==============================] - 396s 305ms/step - loss: 1.4106 - categorical_accuracy: 0.4108 - val_loss: 2.5477 - val_categorical_accuracy: 0.2559\n",
      "Epoch 87/100\n",
      " 400/1300 [========>.....................] - ETA: 4:08 - loss: 1.4076 - categorical_accuracy: 0.4112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 392s 302ms/step - loss: 1.4033 - categorical_accuracy: 0.4134 - val_loss: 2.5351 - val_categorical_accuracy: 0.2575\n",
      "Epoch 92/100\n",
      "1300/1300 [==============================] - 394s 303ms/step - loss: 1.3982 - categorical_accuracy: 0.4131 - val_loss: 2.5526 - val_categorical_accuracy: 0.2572\n",
      "Epoch 93/100\n",
      "1099/1300 [========================>.....] - ETA: 53s - loss: 1.4023 - categorical_accuracy: 0.4128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/1300 [==============================] - 398s 306ms/step - loss: 1.3916 - categorical_accuracy: 0.4146 - val_loss: 2.5811 - val_categorical_accuracy: 0.2525\n",
      "Epoch 99/100\n",
      "1300/1300 [==============================] - 397s 305ms/step - loss: 1.3937 - categorical_accuracy: 0.4133 - val_loss: 2.5619 - val_categorical_accuracy: 0.2502\n",
      "Epoch 100/100\n",
      " 519/1300 [==========>...................] - ETA: 3:29 - loss: 1.3964 - categorical_accuracy: 0.4121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_batches = MagnitudeUtils.batchify(x_train, y_train, BATCH_SIZE) # Split the training data into batches\n",
    "num_batches_per_epoch_train = int(np.ceil(num_training/float(BATCH_SIZE)))\n",
    "test_batches = MagnitudeUtils.batchify(x_test, y_test, BATCH_SIZE)  # Split the test data into batches\n",
    "num_batches_per_epoch_test = int(np.ceil(num_test/float(BATCH_SIZE)))\n",
    "\n",
    "\n",
    "# Generates batches of the transformed training data\n",
    "train_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_train_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_train_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_train_batch, y_train_batch in training_batches\n",
    ")\n",
    "\n",
    "# Generates batches of the transformed test data\n",
    "test_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_test_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_test_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_test_batch, y_test_batch in test_batches\n",
    ")\n",
    "\n",
    "# Start training\n",
    "from keras.utils import np_utils\n",
    "model.fit_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps_per_epoch = num_batches_per_epoch_train,\n",
    "    validation_data = test_batch_generator,\n",
    "    validation_steps = num_batches_per_epoch_test,\n",
    "    epochs = EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after training for 100 epochs:\n",
      "loss: 1.1771 - categorical_accuracy: 0.4449\n",
      "val_loss: 2.5844 - val_categorical_accuracy: 0.2600\n"
     ]
    }
   ],
   "source": [
    "print(\"Results after training for %d epochs:\" % (EPOCHS,))\n",
    "\n",
    "train_metrics = model.evaluate_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps = num_batches_per_epoch_train,\n",
    ")\n",
    "\n",
    "print(\"loss: %.4f - categorical_accuracy: %.4f\" % tuple(train_metrics))\n",
    "\n",
    "val_metrics = model.evaluate_generator(\n",
    "    generator = test_batch_generator,\n",
    "    steps = num_batches_per_epoch_test,\n",
    ")\n",
    "\n",
    "print(\"val_loss: %.4f - val_categorical_accuracy: %.4f\" % tuple(val_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146838"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ehr_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Neural Network\n",
    "-- talk about LSTM vs conv  \n",
    "-- advantages  \n",
    "-- talk about exact model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_25 (GaussianN (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 33)                6633      \n",
      "=================================================================\n",
      "Total params: 247,433\n",
      "Trainable params: 247,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS = 30 # The maximum number of words the sequence model will consider\n",
    "STD_DEV = 0.01 # Deviation of noise for Gaussian Noise applied to the embeddings\n",
    "HIDDEN_UNITS = 100 # The number of hidden units from the LSTM\n",
    "DROPOUT_RATIO = .8 # The ratio to dropout\n",
    "BATCH_SIZE = 100 # The number of examples per train/validation step\n",
    "EPOCHS = 100 # The number of times to repeat through all of the training data\n",
    "LEARNING_RATE = .01 # The learning rate for the optimizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(STD_DEV, input_shape=(MAX_WORDS, med_vectors.dim)))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_UNITS, activation='tanh'), merge_mode='concat'))\n",
    "model.add(Dropout(DROPOUT_RATIO))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=LEARNING_RATE),\n",
    "    metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - 7s 149ms/step - loss: 2.9274 - categorical_accuracy: 0.2484 - val_loss: 2.7295 - val_categorical_accuracy: 0.2823\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.6769 - categorical_accuracy: 0.3016 - val_loss: 2.6813 - val_categorical_accuracy: 0.2893\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.5986 - categorical_accuracy: 0.3022 - val_loss: 2.6024 - val_categorical_accuracy: 0.2983\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.5461 - categorical_accuracy: 0.3066 - val_loss: 2.5599 - val_categorical_accuracy: 0.2973\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.4968 - categorical_accuracy: 0.3158 - val_loss: 2.5194 - val_categorical_accuracy: 0.3113\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.4583 - categorical_accuracy: 0.3216 - val_loss: 2.5165 - val_categorical_accuracy: 0.3113\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.4179 - categorical_accuracy: 0.3274 - val_loss: 2.4992 - val_categorical_accuracy: 0.3083\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.3763 - categorical_accuracy: 0.3364 - val_loss: 2.5250 - val_categorical_accuracy: 0.3123\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.3204 - categorical_accuracy: 0.3432 - val_loss: 2.4775 - val_categorical_accuracy: 0.3133\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.2968 - categorical_accuracy: 0.3462 - val_loss: 2.4748 - val_categorical_accuracy: 0.3133\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.2555 - categorical_accuracy: 0.3552 - val_loss: 2.4877 - val_categorical_accuracy: 0.3003\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.2243 - categorical_accuracy: 0.3568 - val_loss: 2.4676 - val_categorical_accuracy: 0.3163\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.1713 - categorical_accuracy: 0.3682 - val_loss: 2.4720 - val_categorical_accuracy: 0.3113\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.1224 - categorical_accuracy: 0.3822 - val_loss: 2.5004 - val_categorical_accuracy: 0.3053\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 2.1057 - categorical_accuracy: 0.3746 - val_loss: 2.5245 - val_categorical_accuracy: 0.2993\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 2.0479 - categorical_accuracy: 0.3956 - val_loss: 2.5247 - val_categorical_accuracy: 0.3053\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.9986 - categorical_accuracy: 0.4072 - val_loss: 2.5182 - val_categorical_accuracy: 0.3113\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.9805 - categorical_accuracy: 0.4044 - val_loss: 2.5341 - val_categorical_accuracy: 0.3063\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.9066 - categorical_accuracy: 0.4302 - val_loss: 2.6179 - val_categorical_accuracy: 0.3003\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.8568 - categorical_accuracy: 0.4444 - val_loss: 2.6510 - val_categorical_accuracy: 0.3043\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.8774 - categorical_accuracy: 0.4290 - val_loss: 2.5508 - val_categorical_accuracy: 0.3083\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.8287 - categorical_accuracy: 0.4502 - val_loss: 2.6234 - val_categorical_accuracy: 0.3033\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.7762 - categorical_accuracy: 0.4590 - val_loss: 2.6276 - val_categorical_accuracy: 0.3013\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.7759 - categorical_accuracy: 0.4618 - val_loss: 2.6943 - val_categorical_accuracy: 0.3023\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.6664 - categorical_accuracy: 0.4826 - val_loss: 2.7723 - val_categorical_accuracy: 0.2943\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.6572 - categorical_accuracy: 0.4964 - val_loss: 2.7400 - val_categorical_accuracy: 0.2863\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.6326 - categorical_accuracy: 0.5012 - val_loss: 2.8170 - val_categorical_accuracy: 0.2993\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.6204 - categorical_accuracy: 0.5052 - val_loss: 2.7163 - val_categorical_accuracy: 0.3083\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.5777 - categorical_accuracy: 0.5116 - val_loss: 2.7557 - val_categorical_accuracy: 0.3043\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.5479 - categorical_accuracy: 0.5236 - val_loss: 2.8078 - val_categorical_accuracy: 0.3033\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.4854 - categorical_accuracy: 0.5490 - val_loss: 2.8095 - val_categorical_accuracy: 0.2953\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.4960 - categorical_accuracy: 0.5416 - val_loss: 2.8562 - val_categorical_accuracy: 0.2943\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 1.4499 - categorical_accuracy: 0.5498 - val_loss: 2.9154 - val_categorical_accuracy: 0.2993\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 4s 71ms/step - loss: 1.4479 - categorical_accuracy: 0.5532 - val_loss: 2.9327 - val_categorical_accuracy: 0.3003\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 1.4138 - categorical_accuracy: 0.5626 - val_loss: 2.8633 - val_categorical_accuracy: 0.3063\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.4079 - categorical_accuracy: 0.5606 - val_loss: 2.9158 - val_categorical_accuracy: 0.2983\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.3501 - categorical_accuracy: 0.5860 - val_loss: 3.0292 - val_categorical_accuracy: 0.2743\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.3407 - categorical_accuracy: 0.5870 - val_loss: 3.0177 - val_categorical_accuracy: 0.2973\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.3067 - categorical_accuracy: 0.5944 - val_loss: 3.0267 - val_categorical_accuracy: 0.2883\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2970 - categorical_accuracy: 0.6040 - val_loss: 3.0520 - val_categorical_accuracy: 0.3003\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2728 - categorical_accuracy: 0.6070 - val_loss: 3.1022 - val_categorical_accuracy: 0.2923\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2471 - categorical_accuracy: 0.6170 - val_loss: 3.2381 - val_categorical_accuracy: 0.2893\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2170 - categorical_accuracy: 0.6180 - val_loss: 3.1812 - val_categorical_accuracy: 0.2813\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.3802 - categorical_accuracy: 0.5702 - val_loss: 3.0559 - val_categorical_accuracy: 0.3013\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2896 - categorical_accuracy: 0.5970 - val_loss: 3.1357 - val_categorical_accuracy: 0.3023\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.3151 - categorical_accuracy: 0.5988 - val_loss: 3.1093 - val_categorical_accuracy: 0.2783\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.2513 - categorical_accuracy: 0.6174 - val_loss: 3.1085 - val_categorical_accuracy: 0.2833\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2625 - categorical_accuracy: 0.6134 - val_loss: 3.2201 - val_categorical_accuracy: 0.2893\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.3571 - categorical_accuracy: 0.5860 - val_loss: 3.1684 - val_categorical_accuracy: 0.2913\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.2711 - categorical_accuracy: 0.6152 - val_loss: 3.2305 - val_categorical_accuracy: 0.2943\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.2068 - categorical_accuracy: 0.6232 - val_loss: 3.2838 - val_categorical_accuracy: 0.2723\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1972 - categorical_accuracy: 0.6304 - val_loss: 3.2492 - val_categorical_accuracy: 0.2823\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1441 - categorical_accuracy: 0.6414 - val_loss: 3.4235 - val_categorical_accuracy: 0.2753\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1537 - categorical_accuracy: 0.6414 - val_loss: 3.3078 - val_categorical_accuracy: 0.2833\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1142 - categorical_accuracy: 0.6578 - val_loss: 3.2762 - val_categorical_accuracy: 0.2943\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0870 - categorical_accuracy: 0.6568 - val_loss: 3.2938 - val_categorical_accuracy: 0.2903\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0774 - categorical_accuracy: 0.6590 - val_loss: 3.4718 - val_categorical_accuracy: 0.2853\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0975 - categorical_accuracy: 0.6646 - val_loss: 3.4080 - val_categorical_accuracy: 0.2763\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1948 - categorical_accuracy: 0.6308 - val_loss: 3.3044 - val_categorical_accuracy: 0.2743\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.1099 - categorical_accuracy: 0.6590 - val_loss: 3.3226 - val_categorical_accuracy: 0.2813\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0816 - categorical_accuracy: 0.6578 - val_loss: 3.5478 - val_categorical_accuracy: 0.2703\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0872 - categorical_accuracy: 0.6644 - val_loss: 3.3893 - val_categorical_accuracy: 0.2833\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.0747 - categorical_accuracy: 0.6660 - val_loss: 3.4140 - val_categorical_accuracy: 0.2853\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0450 - categorical_accuracy: 0.6652 - val_loss: 3.4703 - val_categorical_accuracy: 0.2743\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.0399 - categorical_accuracy: 0.6742 - val_loss: 3.4843 - val_categorical_accuracy: 0.2703\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0336 - categorical_accuracy: 0.6756 - val_loss: 3.4749 - val_categorical_accuracy: 0.2803\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0210 - categorical_accuracy: 0.6814 - val_loss: 3.4838 - val_categorical_accuracy: 0.2723\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0256 - categorical_accuracy: 0.6774 - val_loss: 3.5121 - val_categorical_accuracy: 0.2873\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 1.0733 - categorical_accuracy: 0.6694 - val_loss: 3.4983 - val_categorical_accuracy: 0.2823\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 1.0772 - categorical_accuracy: 0.6622 - val_loss: 3.4550 - val_categorical_accuracy: 0.2923\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9826 - categorical_accuracy: 0.6928 - val_loss: 3.5539 - val_categorical_accuracy: 0.2813\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.9922 - categorical_accuracy: 0.6836 - val_loss: 3.5888 - val_categorical_accuracy: 0.2763\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9758 - categorical_accuracy: 0.6958 - val_loss: 3.5695 - val_categorical_accuracy: 0.2773\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9871 - categorical_accuracy: 0.6934 - val_loss: 3.5950 - val_categorical_accuracy: 0.2863\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9929 - categorical_accuracy: 0.6976 - val_loss: 3.6428 - val_categorical_accuracy: 0.2723\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9684 - categorical_accuracy: 0.6926 - val_loss: 3.6693 - val_categorical_accuracy: 0.2683\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9335 - categorical_accuracy: 0.7106 - val_loss: 3.6886 - val_categorical_accuracy: 0.2683\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9813 - categorical_accuracy: 0.6868 - val_loss: 3.7207 - val_categorical_accuracy: 0.2903\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9027 - categorical_accuracy: 0.7186 - val_loss: 3.7184 - val_categorical_accuracy: 0.2753\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9099 - categorical_accuracy: 0.7108 - val_loss: 3.7106 - val_categorical_accuracy: 0.2783\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9044 - categorical_accuracy: 0.7150 - val_loss: 3.7366 - val_categorical_accuracy: 0.2743\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8817 - categorical_accuracy: 0.7176 - val_loss: 3.7302 - val_categorical_accuracy: 0.2813\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9201 - categorical_accuracy: 0.7168 - val_loss: 3.7239 - val_categorical_accuracy: 0.2783\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9005 - categorical_accuracy: 0.7222 - val_loss: 3.5738 - val_categorical_accuracy: 0.2723\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9075 - categorical_accuracy: 0.7126 - val_loss: 3.8080 - val_categorical_accuracy: 0.2693\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.8591 - categorical_accuracy: 0.7344 - val_loss: 3.6164 - val_categorical_accuracy: 0.2823\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.8693 - categorical_accuracy: 0.7308 - val_loss: 3.7940 - val_categorical_accuracy: 0.2743\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.9021 - categorical_accuracy: 0.7232 - val_loss: 3.6639 - val_categorical_accuracy: 0.2713\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.9062 - categorical_accuracy: 0.7214 - val_loss: 3.9401 - val_categorical_accuracy: 0.2663\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 3s 66ms/step - loss: 0.8708 - categorical_accuracy: 0.7246 - val_loss: 3.8233 - val_categorical_accuracy: 0.2613\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 4s 74ms/step - loss: 0.8284 - categorical_accuracy: 0.7432 - val_loss: 4.0048 - val_categorical_accuracy: 0.2603\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 0.8172 - categorical_accuracy: 0.7476 - val_loss: 3.9468 - val_categorical_accuracy: 0.2733\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.8388 - categorical_accuracy: 0.7386 - val_loss: 3.8396 - val_categorical_accuracy: 0.2713\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8154 - categorical_accuracy: 0.7516 - val_loss: 3.9872 - val_categorical_accuracy: 0.2633\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8194 - categorical_accuracy: 0.7490 - val_loss: 4.0691 - val_categorical_accuracy: 0.2683\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8662 - categorical_accuracy: 0.7268 - val_loss: 3.9048 - val_categorical_accuracy: 0.2663\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8330 - categorical_accuracy: 0.7396 - val_loss: 3.8627 - val_categorical_accuracy: 0.2583\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 0.8675 - categorical_accuracy: 0.7334 - val_loss: 4.0077 - val_categorical_accuracy: 0.2643\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8306 - categorical_accuracy: 0.7400 - val_loss: 3.7670 - val_categorical_accuracy: 0.2683\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8342 - categorical_accuracy: 0.7398 - val_loss: 4.0257 - val_categorical_accuracy: 0.2643\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8146 - categorical_accuracy: 0.7514 - val_loss: 3.8496 - val_categorical_accuracy: 0.2533\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7863 - categorical_accuracy: 0.7582 - val_loss: 3.9310 - val_categorical_accuracy: 0.2673\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7687 - categorical_accuracy: 0.7504 - val_loss: 4.0908 - val_categorical_accuracy: 0.2703\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7275 - categorical_accuracy: 0.7700 - val_loss: 4.0067 - val_categorical_accuracy: 0.2523\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.7177 - categorical_accuracy: 0.7772 - val_loss: 4.1642 - val_categorical_accuracy: 0.2583\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.7268 - categorical_accuracy: 0.7748 - val_loss: 4.1133 - val_categorical_accuracy: 0.2613\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.6970 - categorical_accuracy: 0.7826 - val_loss: 4.0651 - val_categorical_accuracy: 0.2723\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7234 - categorical_accuracy: 0.7810 - val_loss: 4.0518 - val_categorical_accuracy: 0.2803\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7345 - categorical_accuracy: 0.7722 - val_loss: 4.1805 - val_categorical_accuracy: 0.2683\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7035 - categorical_accuracy: 0.7798 - val_loss: 4.1053 - val_categorical_accuracy: 0.2613\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6807 - categorical_accuracy: 0.7854 - val_loss: 4.2991 - val_categorical_accuracy: 0.2543\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.8135 - categorical_accuracy: 0.7560 - val_loss: 3.9730 - val_categorical_accuracy: 0.2703\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7337 - categorical_accuracy: 0.7734 - val_loss: 4.2793 - val_categorical_accuracy: 0.2543\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.9223 - categorical_accuracy: 0.7352 - val_loss: 3.9078 - val_categorical_accuracy: 0.2553\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8815 - categorical_accuracy: 0.7260 - val_loss: 4.1174 - val_categorical_accuracy: 0.2643\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.8201 - categorical_accuracy: 0.7498 - val_loss: 4.0129 - val_categorical_accuracy: 0.2683\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7733 - categorical_accuracy: 0.7668 - val_loss: 4.1242 - val_categorical_accuracy: 0.2533\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7324 - categorical_accuracy: 0.7798 - val_loss: 4.0868 - val_categorical_accuracy: 0.2763\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.7135 - categorical_accuracy: 0.7764 - val_loss: 4.1403 - val_categorical_accuracy: 0.2723\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6471 - categorical_accuracy: 0.7986 - val_loss: 4.2309 - val_categorical_accuracy: 0.2723\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6363 - categorical_accuracy: 0.8002 - val_loss: 4.2601 - val_categorical_accuracy: 0.2663\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6281 - categorical_accuracy: 0.8032 - val_loss: 4.3591 - val_categorical_accuracy: 0.2783\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.6036 - categorical_accuracy: 0.8120 - val_loss: 4.4833 - val_categorical_accuracy: 0.2553\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 0.5900 - categorical_accuracy: 0.8104 - val_loss: 4.5752 - val_categorical_accuracy: 0.2603\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.6473 - categorical_accuracy: 0.7968 - val_loss: 4.3291 - val_categorical_accuracy: 0.2663\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6496 - categorical_accuracy: 0.8000 - val_loss: 4.4683 - val_categorical_accuracy: 0.2583\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6454 - categorical_accuracy: 0.7978 - val_loss: 4.5059 - val_categorical_accuracy: 0.2833\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6623 - categorical_accuracy: 0.8000 - val_loss: 4.4210 - val_categorical_accuracy: 0.2803\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6387 - categorical_accuracy: 0.8004 - val_loss: 4.3632 - val_categorical_accuracy: 0.2873\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6339 - categorical_accuracy: 0.8044 - val_loss: 4.4603 - val_categorical_accuracy: 0.2523\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6215 - categorical_accuracy: 0.8036 - val_loss: 4.3992 - val_categorical_accuracy: 0.2783\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.6017 - categorical_accuracy: 0.8102 - val_loss: 4.5096 - val_categorical_accuracy: 0.2793\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6413 - categorical_accuracy: 0.8000 - val_loss: 4.4164 - val_categorical_accuracy: 0.2482\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.8258 - categorical_accuracy: 0.7534 - val_loss: 4.6625 - val_categorical_accuracy: 0.2573\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 1.0055 - categorical_accuracy: 0.7116 - val_loss: 4.0638 - val_categorical_accuracy: 0.2893\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.8329 - categorical_accuracy: 0.7436 - val_loss: 4.2382 - val_categorical_accuracy: 0.2713\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 0.7578 - categorical_accuracy: 0.7630 - val_loss: 4.5230 - val_categorical_accuracy: 0.2663\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 3s 70ms/step - loss: 0.7010 - categorical_accuracy: 0.7886 - val_loss: 4.3980 - val_categorical_accuracy: 0.2673\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 3s 70ms/step - loss: 0.7370 - categorical_accuracy: 0.7772 - val_loss: 4.2920 - val_categorical_accuracy: 0.2843\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.6541 - categorical_accuracy: 0.7954 - val_loss: 4.3737 - val_categorical_accuracy: 0.2713\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6534 - categorical_accuracy: 0.7932 - val_loss: 4.3495 - val_categorical_accuracy: 0.2683\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6505 - categorical_accuracy: 0.7958 - val_loss: 4.5269 - val_categorical_accuracy: 0.2653\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6166 - categorical_accuracy: 0.8074 - val_loss: 4.4603 - val_categorical_accuracy: 0.2673\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6049 - categorical_accuracy: 0.8060 - val_loss: 4.5230 - val_categorical_accuracy: 0.2853\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.6079 - categorical_accuracy: 0.8110 - val_loss: 4.6439 - val_categorical_accuracy: 0.2653\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6008 - categorical_accuracy: 0.8060 - val_loss: 4.6839 - val_categorical_accuracy: 0.2683\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5627 - categorical_accuracy: 0.8230 - val_loss: 4.5992 - val_categorical_accuracy: 0.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5627 - categorical_accuracy: 0.8248 - val_loss: 4.8831 - val_categorical_accuracy: 0.2543\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5315 - categorical_accuracy: 0.8362 - val_loss: 4.5654 - val_categorical_accuracy: 0.2663\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5323 - categorical_accuracy: 0.8378 - val_loss: 4.8099 - val_categorical_accuracy: 0.2683\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5069 - categorical_accuracy: 0.8468 - val_loss: 4.6621 - val_categorical_accuracy: 0.2643\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5370 - categorical_accuracy: 0.8346 - val_loss: 5.0473 - val_categorical_accuracy: 0.2673\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5540 - categorical_accuracy: 0.8318 - val_loss: 4.8810 - val_categorical_accuracy: 0.2513\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5616 - categorical_accuracy: 0.8242 - val_loss: 4.7096 - val_categorical_accuracy: 0.2693\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5347 - categorical_accuracy: 0.8386 - val_loss: 4.7051 - val_categorical_accuracy: 0.2643\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5181 - categorical_accuracy: 0.8396 - val_loss: 4.8600 - val_categorical_accuracy: 0.2613\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5380 - categorical_accuracy: 0.8310 - val_loss: 4.9071 - val_categorical_accuracy: 0.2643\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5183 - categorical_accuracy: 0.8390 - val_loss: 4.9492 - val_categorical_accuracy: 0.2583\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5134 - categorical_accuracy: 0.8416 - val_loss: 4.7595 - val_categorical_accuracy: 0.2643\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4945 - categorical_accuracy: 0.8388 - val_loss: 4.8659 - val_categorical_accuracy: 0.2613\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5160 - categorical_accuracy: 0.8410 - val_loss: 4.9333 - val_categorical_accuracy: 0.2703\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5008 - categorical_accuracy: 0.8486 - val_loss: 4.7648 - val_categorical_accuracy: 0.2753\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5451 - categorical_accuracy: 0.8282 - val_loss: 4.7995 - val_categorical_accuracy: 0.2703\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.6182 - categorical_accuracy: 0.8072 - val_loss: 4.6233 - val_categorical_accuracy: 0.2563\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.6744 - categorical_accuracy: 0.7974 - val_loss: 4.7587 - val_categorical_accuracy: 0.2613\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5854 - categorical_accuracy: 0.8158 - val_loss: 4.7922 - val_categorical_accuracy: 0.2643\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5786 - categorical_accuracy: 0.8232 - val_loss: 4.8732 - val_categorical_accuracy: 0.2593\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.6127 - categorical_accuracy: 0.8098 - val_loss: 4.7548 - val_categorical_accuracy: 0.2523\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5630 - categorical_accuracy: 0.8228 - val_loss: 4.8329 - val_categorical_accuracy: 0.2653\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5524 - categorical_accuracy: 0.8340 - val_loss: 5.0861 - val_categorical_accuracy: 0.2683\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.6169 - categorical_accuracy: 0.8146 - val_loss: 4.8215 - val_categorical_accuracy: 0.2653\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5424 - categorical_accuracy: 0.8270 - val_loss: 4.7299 - val_categorical_accuracy: 0.2773\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4976 - categorical_accuracy: 0.8442 - val_loss: 4.9561 - val_categorical_accuracy: 0.2663\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.4967 - categorical_accuracy: 0.8454 - val_loss: 4.8496 - val_categorical_accuracy: 0.2813\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4824 - categorical_accuracy: 0.8470 - val_loss: 4.9659 - val_categorical_accuracy: 0.2733\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4865 - categorical_accuracy: 0.8450 - val_loss: 4.8592 - val_categorical_accuracy: 0.2683\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5217 - categorical_accuracy: 0.8364 - val_loss: 4.7893 - val_categorical_accuracy: 0.2743\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5308 - categorical_accuracy: 0.8410 - val_loss: 4.9285 - val_categorical_accuracy: 0.2643\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5582 - categorical_accuracy: 0.8254 - val_loss: 4.9338 - val_categorical_accuracy: 0.2623\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5444 - categorical_accuracy: 0.8328 - val_loss: 4.9657 - val_categorical_accuracy: 0.2613\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5578 - categorical_accuracy: 0.8300 - val_loss: 4.8531 - val_categorical_accuracy: 0.2523\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5363 - categorical_accuracy: 0.8322 - val_loss: 4.8685 - val_categorical_accuracy: 0.2713\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5112 - categorical_accuracy: 0.8372 - val_loss: 4.8505 - val_categorical_accuracy: 0.2593\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5481 - categorical_accuracy: 0.8294 - val_loss: 4.8800 - val_categorical_accuracy: 0.2533\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5220 - categorical_accuracy: 0.8396 - val_loss: 5.1306 - val_categorical_accuracy: 0.2553\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.5035 - categorical_accuracy: 0.8382 - val_loss: 5.0689 - val_categorical_accuracy: 0.2503\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4707 - categorical_accuracy: 0.8560 - val_loss: 5.1312 - val_categorical_accuracy: 0.2633\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4621 - categorical_accuracy: 0.8494 - val_loss: 5.0981 - val_categorical_accuracy: 0.2583\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4822 - categorical_accuracy: 0.8466 - val_loss: 5.0101 - val_categorical_accuracy: 0.2513\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4658 - categorical_accuracy: 0.8528 - val_loss: 5.1268 - val_categorical_accuracy: 0.2553\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4624 - categorical_accuracy: 0.8568 - val_loss: 5.2199 - val_categorical_accuracy: 0.2543\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4764 - categorical_accuracy: 0.8520 - val_loss: 5.1194 - val_categorical_accuracy: 0.2613\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4453 - categorical_accuracy: 0.8596 - val_loss: 5.5007 - val_categorical_accuracy: 0.2643\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 0.4440 - categorical_accuracy: 0.8624 - val_loss: 5.0746 - val_categorical_accuracy: 0.2583\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 4s 70ms/step - loss: 0.4326 - categorical_accuracy: 0.8678 - val_loss: 5.3482 - val_categorical_accuracy: 0.2533\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 0.4146 - categorical_accuracy: 0.8674 - val_loss: 5.4291 - val_categorical_accuracy: 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4326 - categorical_accuracy: 0.8634 - val_loss: 5.4545 - val_categorical_accuracy: 0.2523\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.4643 - categorical_accuracy: 0.8572 - val_loss: 5.1968 - val_categorical_accuracy: 0.2643\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.5010 - categorical_accuracy: 0.8486 - val_loss: 5.0827 - val_categorical_accuracy: 0.2593\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.4954 - categorical_accuracy: 0.8478 - val_loss: 5.0370 - val_categorical_accuracy: 0.2492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e697db198>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_batches = MagnitudeUtils.batchify(x_train, y_train, BATCH_SIZE) # Split the training data into batches\n",
    "num_batches_per_epoch_train = int(np.ceil(num_training/float(BATCH_SIZE)))\n",
    "test_batches = MagnitudeUtils.batchify(x_test, y_test, BATCH_SIZE)  # Split the test data into batches\n",
    "num_batches_per_epoch_test = int(np.ceil(num_test/float(BATCH_SIZE)))\n",
    "\n",
    "# Generates batches of the transformed training data\n",
    "train_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_train_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_train_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_train_batch, y_train_batch in training_batches\n",
    ")\n",
    "\n",
    "# Generates batches of the transformed test data\n",
    "test_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_test_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_test_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_test_batch, y_test_batch in test_batches\n",
    ")\n",
    "\n",
    "# Start training\n",
    "from keras.utils import np_utils\n",
    "model.fit_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps_per_epoch = num_batches_per_epoch_train,\n",
    "    validation_data = test_batch_generator,\n",
    "    validation_steps = num_batches_per_epoch_test,\n",
    "    epochs = EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after training for 100 epochs:\n",
      "loss: 0.1476 - categorical_accuracy: 0.9353\n",
      "val_loss: 6.9081 - val_categorical_accuracy: 0.2211\n"
     ]
    }
   ],
   "source": [
    "print(\"Results after training for %d epochs:\" % (EPOCHS,))\n",
    "\n",
    "train_metrics = model.evaluate_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps = num_batches_per_epoch_train,\n",
    ")\n",
    "\n",
    "print(\"loss: %.4f - categorical_accuracy: %.4f\" % tuple(train_metrics))\n",
    "\n",
    "val_metrics = model.evaluate_generator(\n",
    "    generator = test_batch_generator,\n",
    "    steps = num_batches_per_epoch_test,\n",
    ")\n",
    "\n",
    "print(\"val_loss: %.4f - val_categorical_accuracy: %.4f\" % tuple(val_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 30 # The maximum number of words the sequence model will consider\n",
    "STD_DEV = 0.01 # Deviation of noise for Gaussian Noise applied to the embeddings\n",
    "HIDDEN_UNITS = 50 # The number of hidden units from the LSTM\n",
    "DROPOUT_RATIO = .8 # The ratio to dropout\n",
    "BATCH_SIZE = 100 # The number of examples per train/validation step\n",
    "EPOCHS = 200 # The number of times to repeat through all of the training data\n",
    "LEARNING_RATE = .001 # The learning rate for the optimizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(STD_DEV, input_shape=(MAX_WORDS, med_vectors.dim)))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_UNITS, activation='tanh'), merge_mode='concat'))\n",
    "model.add(Dropout(DROPOUT_RATIO))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=LEARNING_RATE),\n",
    "    metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 1/200\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 3.3734 - categorical_accuracy: 0.1648 - val_loss: 2.9762 - val_categorical_accuracy: 0.2162\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 3.3734 - categorical_accuracy: 0.1648 - val_loss: 2.9762 - val_categorical_accuracy: 0.2162\n",
      "Epoch 2/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 3.0341 - categorical_accuracy: 0.2100Epoch 2/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.9959 - categorical_accuracy: 0.2158 - val_loss: 2.8867 - val_categorical_accuracy: 0.2242\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.9959 - categorical_accuracy: 0.2158 - val_loss: 2.8867 - val_categorical_accuracy: 0.2242\n",
      "Epoch 3/200\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.8914 - categorical_accuracy: 0.2484 - val_loss: 2.8114 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.8914 - categorical_accuracy: 0.2484 - val_loss: 2.8114 - val_categorical_accuracy: 0.2873\n",
      "Epoch 4/200\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 2.8265 - categorical_accuracy: 0.2662 - val_loss: 2.7694 - val_categorical_accuracy: 0.2883\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 2.8265 - categorical_accuracy: 0.2662 - val_loss: 2.7694 - val_categorical_accuracy: 0.2883\n",
      "Epoch 5/200\n",
      " 1/50 [..............................] - ETA: 3s - loss: 2.7613 - categorical_accuracy: 0.3100Epoch 5/200\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 2.7888 - categorical_accuracy: 0.2798 - val_loss: 2.7349 - val_categorical_accuracy: 0.2923\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 2.7888 - categorical_accuracy: 0.2798 - val_loss: 2.7349 - val_categorical_accuracy: 0.2923\n",
      "Epoch 6/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.6345 - categorical_accuracy: 0.2800Epoch 6/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.7507 - categorical_accuracy: 0.2888 - val_loss: 2.7151 - val_categorical_accuracy: 0.2913\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.7507 - categorical_accuracy: 0.2888 - val_loss: 2.7151 - val_categorical_accuracy: 0.2913\n",
      "Epoch 7/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.6175 - categorical_accuracy: 0.2500Epoch 7/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.7188 - categorical_accuracy: 0.2918 - val_loss: 2.6947 - val_categorical_accuracy: 0.2923\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.7188 - categorical_accuracy: 0.2918 - val_loss: 2.6947 - val_categorical_accuracy: 0.2923\n",
      "Epoch 8/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.6593 - categorical_accuracy: 0.3200Epoch 8/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.6877 - categorical_accuracy: 0.2986 - val_loss: 2.6643 - val_categorical_accuracy: 0.2953\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.6877 - categorical_accuracy: 0.2986 - val_loss: 2.6643 - val_categorical_accuracy: 0.2953\n",
      "Epoch 9/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.6224 - categorical_accuracy: 0.2900Epoch 9/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.6664 - categorical_accuracy: 0.2950 - val_loss: 2.6447 - val_categorical_accuracy: 0.2993\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.6664 - categorical_accuracy: 0.2950 - val_loss: 2.6447 - val_categorical_accuracy: 0.2993\n",
      "Epoch 10/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.5555 - categorical_accuracy: 0.2800Epoch 10/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.6379 - categorical_accuracy: 0.2990 - val_loss: 2.6272 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.6379 - categorical_accuracy: 0.2990 - val_loss: 2.6272 - val_categorical_accuracy: 0.3013\n",
      "Epoch 11/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.5168 - categorical_accuracy: 0.3100Epoch 11/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.6192 - categorical_accuracy: 0.3010 - val_loss: 2.6212 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.6192 - categorical_accuracy: 0.3010 - val_loss: 2.6212 - val_categorical_accuracy: 0.3013\n",
      "Epoch 12/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.5317 - categorical_accuracy: 0.3600Epoch 12/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.6001 - categorical_accuracy: 0.3118 - val_loss: 2.6168 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.6001 - categorical_accuracy: 0.3118 - val_loss: 2.6168 - val_categorical_accuracy: 0.3043\n",
      "Epoch 13/200\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5773 - categorical_accuracy: 0.3100 - val_loss: 2.5927 - val_categorical_accuracy: 0.3053\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5773 - categorical_accuracy: 0.3100 - val_loss: 2.5927 - val_categorical_accuracy: 0.3053\n",
      "Epoch 14/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.4910 - categorical_accuracy: 0.3300Epoch 14/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.5698 - categorical_accuracy: 0.3112 - val_loss: 2.5930 - val_categorical_accuracy: 0.3103\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.5698 - categorical_accuracy: 0.3112 - val_loss: 2.5930 - val_categorical_accuracy: 0.3103\n",
      "Epoch 15/200\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5427 - categorical_accuracy: 0.3162 - val_loss: 2.5938 - val_categorical_accuracy: 0.3093\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5427 - categorical_accuracy: 0.3162 - val_loss: 2.5938 - val_categorical_accuracy: 0.3093\n",
      "Epoch 16/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.3985 - categorical_accuracy: 0.3600Epoch 16/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5342 - categorical_accuracy: 0.3156 - val_loss: 2.5821 - val_categorical_accuracy: 0.3123\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5342 - categorical_accuracy: 0.3156 - val_loss: 2.5821 - val_categorical_accuracy: 0.3123\n",
      "Epoch 17/200\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5327 - categorical_accuracy: 0.3104 - val_loss: 2.5903 - val_categorical_accuracy: 0.3103\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5327 - categorical_accuracy: 0.3104 - val_loss: 2.5903 - val_categorical_accuracy: 0.3103\n",
      "Epoch 18/200\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.5065 - categorical_accuracy: 0.3138 - val_loss: 2.5662 - val_categorical_accuracy: 0.3093\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.5065 - categorical_accuracy: 0.3138 - val_loss: 2.5662 - val_categorical_accuracy: 0.3093\n",
      "Epoch 19/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.3053 - categorical_accuracy: 0.4100Epoch 19/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4970 - categorical_accuracy: 0.3214 - val_loss: 2.5601 - val_categorical_accuracy: 0.3123\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4970 - categorical_accuracy: 0.3214 - val_loss: 2.5601 - val_categorical_accuracy: 0.3123\n",
      "Epoch 20/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.4256 - categorical_accuracy: 0.3300Epoch 20/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4987 - categorical_accuracy: 0.3230 - val_loss: 2.5646 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4987 - categorical_accuracy: 0.3230 - val_loss: 2.5646 - val_categorical_accuracy: 0.3133\n",
      "Epoch 21/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.4905 - categorical_accuracy: 0.3100Epoch 21/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4865 - categorical_accuracy: 0.3164 - val_loss: 2.5607 - val_categorical_accuracy: 0.3153\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4865 - categorical_accuracy: 0.3164 - val_loss: 2.5607 - val_categorical_accuracy: 0.3153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4821 - categorical_accuracy: 0.3220 - val_loss: 2.5591 - val_categorical_accuracy: 0.3113\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4821 - categorical_accuracy: 0.3220 - val_loss: 2.5591 - val_categorical_accuracy: 0.3113\n",
      "Epoch 23/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.3776 - categorical_accuracy: 0.3200Epoch 23/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4632 - categorical_accuracy: 0.3210 - val_loss: 2.5620 - val_categorical_accuracy: 0.3153\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4632 - categorical_accuracy: 0.3210 - val_loss: 2.5620 - val_categorical_accuracy: 0.3153\n",
      "Epoch 24/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.3930 - categorical_accuracy: 0.3000Epoch 24/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4613 - categorical_accuracy: 0.3228 - val_loss: 2.5562 - val_categorical_accuracy: 0.3113\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4613 - categorical_accuracy: 0.3228 - val_loss: 2.5562 - val_categorical_accuracy: 0.3113\n",
      "Epoch 25/200\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4418 - categorical_accuracy: 0.3254 - val_loss: 2.5418 - val_categorical_accuracy: 0.3153\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4418 - categorical_accuracy: 0.3254 - val_loss: 2.5418 - val_categorical_accuracy: 0.3153\n",
      "Epoch 26/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.3434 - categorical_accuracy: 0.3200Epoch 26/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4340 - categorical_accuracy: 0.3236 - val_loss: 2.5582 - val_categorical_accuracy: 0.3143\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.4340 - categorical_accuracy: 0.3236 - val_loss: 2.5582 - val_categorical_accuracy: 0.3143\n",
      "Epoch 27/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.3633 - categorical_accuracy: 0.3400Epoch 27/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4441 - categorical_accuracy: 0.3240 - val_loss: 2.5590 - val_categorical_accuracy: 0.3173\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4441 - categorical_accuracy: 0.3240 - val_loss: 2.5590 - val_categorical_accuracy: 0.3173\n",
      "Epoch 28/200\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4137 - categorical_accuracy: 0.3306 - val_loss: 2.5442 - val_categorical_accuracy: 0.3093\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4137 - categorical_accuracy: 0.3306 - val_loss: 2.5442 - val_categorical_accuracy: 0.3093\n",
      "Epoch 29/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.3353 - categorical_accuracy: 0.3500Epoch 29/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4208 - categorical_accuracy: 0.3308 - val_loss: 2.5453 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.4208 - categorical_accuracy: 0.3308 - val_loss: 2.5453 - val_categorical_accuracy: 0.3133\n",
      "Epoch 30/200\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4124 - categorical_accuracy: 0.3286 - val_loss: 2.5452 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.4124 - categorical_accuracy: 0.3286 - val_loss: 2.5452 - val_categorical_accuracy: 0.3133\n",
      "Epoch 31/200\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3785 - categorical_accuracy: 0.3300 - val_loss: 2.5612 - val_categorical_accuracy: 0.3113\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3785 - categorical_accuracy: 0.3300 - val_loss: 2.5612 - val_categorical_accuracy: 0.3113\n",
      "Epoch 32/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2413 - categorical_accuracy: 0.3600Epoch 32/200\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.3741 - categorical_accuracy: 0.3352 - val_loss: 2.5432 - val_categorical_accuracy: 0.3233\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.3741 - categorical_accuracy: 0.3352 - val_loss: 2.5432 - val_categorical_accuracy: 0.3233\n",
      "Epoch 33/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.3049 - categorical_accuracy: 0.3100Epoch 33/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3870 - categorical_accuracy: 0.3318 - val_loss: 2.5462 - val_categorical_accuracy: 0.3173\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3870 - categorical_accuracy: 0.3318 - val_loss: 2.5462 - val_categorical_accuracy: 0.3173\n",
      "Epoch 34/200\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3711 - categorical_accuracy: 0.3376 - val_loss: 2.5568 - val_categorical_accuracy: 0.3143\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3711 - categorical_accuracy: 0.3376 - val_loss: 2.5568 - val_categorical_accuracy: 0.3143\n",
      "Epoch 35/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2684 - categorical_accuracy: 0.3600Epoch 35/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3531 - categorical_accuracy: 0.3386 - val_loss: 2.5507 - val_categorical_accuracy: 0.3083\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3531 - categorical_accuracy: 0.3386 - val_loss: 2.5507 - val_categorical_accuracy: 0.3083\n",
      "Epoch 36/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2750 - categorical_accuracy: 0.3600Epoch 36/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3464 - categorical_accuracy: 0.3440 - val_loss: 2.5639 - val_categorical_accuracy: 0.3163\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3464 - categorical_accuracy: 0.3440 - val_loss: 2.5639 - val_categorical_accuracy: 0.3163\n",
      "Epoch 37/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.1459 - categorical_accuracy: 0.3200Epoch 37/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3370 - categorical_accuracy: 0.3418 - val_loss: 2.5794 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3370 - categorical_accuracy: 0.3418 - val_loss: 2.5794 - val_categorical_accuracy: 0.3043\n",
      "Epoch 38/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2493 - categorical_accuracy: 0.3600Epoch 38/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.3410 - categorical_accuracy: 0.3392 - val_loss: 2.5540 - val_categorical_accuracy: 0.3103\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.3410 - categorical_accuracy: 0.3392 - val_loss: 2.5540 - val_categorical_accuracy: 0.3103\n",
      "Epoch 39/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.1600 - categorical_accuracy: 0.3800Epoch 39/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3184 - categorical_accuracy: 0.3416 - val_loss: 2.5568 - val_categorical_accuracy: 0.3173\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.3184 - categorical_accuracy: 0.3416 - val_loss: 2.5568 - val_categorical_accuracy: 0.3173\n",
      "Epoch 40/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2597 - categorical_accuracy: 0.3600Epoch 40/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.3332 - categorical_accuracy: 0.3408 - val_loss: 2.5707 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.3332 - categorical_accuracy: 0.3408 - val_loss: 2.5707 - val_categorical_accuracy: 0.3133\n",
      "Epoch 41/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1612 - categorical_accuracy: 0.4000Epoch 41/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2991 - categorical_accuracy: 0.3466 - val_loss: 2.5693 - val_categorical_accuracy: 0.3113\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2991 - categorical_accuracy: 0.3466 - val_loss: 2.5693 - val_categorical_accuracy: 0.3113\n",
      "Epoch 42/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1391 - categorical_accuracy: 0.4000Epoch 42/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2946 - categorical_accuracy: 0.3460 - val_loss: 2.5818 - val_categorical_accuracy: 0.3033\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2946 - categorical_accuracy: 0.3460 - val_loss: 2.5818 - val_categorical_accuracy: 0.3033\n",
      "Epoch 43/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1876 - categorical_accuracy: 0.3500Epoch 43/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2963 - categorical_accuracy: 0.3508 - val_loss: 2.5886 - val_categorical_accuracy: 0.3103\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2963 - categorical_accuracy: 0.3508 - val_loss: 2.5886 - val_categorical_accuracy: 0.3103\n",
      "Epoch 44/200\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2859 - categorical_accuracy: 0.3534 - val_loss: 2.6012 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2859 - categorical_accuracy: 0.3534 - val_loss: 2.6012 - val_categorical_accuracy: 0.3133\n",
      "Epoch 45/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2300 - categorical_accuracy: 0.3500Epoch 45/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2809 - categorical_accuracy: 0.3446 - val_loss: 2.5980 - val_categorical_accuracy: 0.3183\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2809 - categorical_accuracy: 0.3446 - val_loss: 2.5980 - val_categorical_accuracy: 0.3183\n",
      "Epoch 46/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2193 - categorical_accuracy: 0.3600Epoch 46/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2833 - categorical_accuracy: 0.3508 - val_loss: 2.5836 - val_categorical_accuracy: 0.3133\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2833 - categorical_accuracy: 0.3508 - val_loss: 2.5836 - val_categorical_accuracy: 0.3133\n",
      "Epoch 47/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2584 - categorical_accuracy: 0.3200Epoch 47/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2710 - categorical_accuracy: 0.3522 - val_loss: 2.5871 - val_categorical_accuracy: 0.3053\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2710 - categorical_accuracy: 0.3522 - val_loss: 2.5871 - val_categorical_accuracy: 0.3053\n",
      "Epoch 48/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1805 - categorical_accuracy: 0.3100Epoch 48/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2715 - categorical_accuracy: 0.3476 - val_loss: 2.6061 - val_categorical_accuracy: 0.3103\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2715 - categorical_accuracy: 0.3476 - val_loss: 2.6061 - val_categorical_accuracy: 0.3103\n",
      "Epoch 49/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1768 - categorical_accuracy: 0.3400Epoch 49/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2503 - categorical_accuracy: 0.3574 - val_loss: 2.5815 - val_categorical_accuracy: 0.2983\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2503 - categorical_accuracy: 0.3574 - val_loss: 2.5815 - val_categorical_accuracy: 0.2983\n",
      "Epoch 50/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2492 - categorical_accuracy: 0.3900Epoch 50/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2343 - categorical_accuracy: 0.3644 - val_loss: 2.6262 - val_categorical_accuracy: 0.3063\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2343 - categorical_accuracy: 0.3644 - val_loss: 2.6262 - val_categorical_accuracy: 0.3063\n",
      "Epoch 51/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.0535 - categorical_accuracy: 0.4000Epoch 51/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2287 - categorical_accuracy: 0.3584 - val_loss: 2.6398 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2287 - categorical_accuracy: 0.3584 - val_loss: 2.6398 - val_categorical_accuracy: 0.3013\n",
      "Epoch 52/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1172 - categorical_accuracy: 0.4000Epoch 52/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2266 - categorical_accuracy: 0.3506 - val_loss: 2.6428 - val_categorical_accuracy: 0.2983\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.2266 - categorical_accuracy: 0.3506 - val_loss: 2.6428 - val_categorical_accuracy: 0.2983\n",
      "Epoch 53/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2000 - categorical_accuracy: 0.3300Epoch 53/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2198 - categorical_accuracy: 0.3618 - val_loss: 2.6119 - val_categorical_accuracy: 0.3063\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.2198 - categorical_accuracy: 0.3618 - val_loss: 2.6119 - val_categorical_accuracy: 0.3063\n",
      "Epoch 54/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1967 - categorical_accuracy: 0.3000Epoch 54/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2174 - categorical_accuracy: 0.3656 - val_loss: 2.6218 - val_categorical_accuracy: 0.3083\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2174 - categorical_accuracy: 0.3656 - val_loss: 2.6218 - val_categorical_accuracy: 0.3083\n",
      "Epoch 55/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.1305 - categorical_accuracy: 0.3400Epoch 55/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2064 - categorical_accuracy: 0.3610 - val_loss: 2.6680 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2064 - categorical_accuracy: 0.3610 - val_loss: 2.6680 - val_categorical_accuracy: 0.3023\n",
      "Epoch 56/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2018 - categorical_accuracy: 0.3600Epoch 56/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2312 - categorical_accuracy: 0.3590 - val_loss: 2.6618 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2312 - categorical_accuracy: 0.3590 - val_loss: 2.6618 - val_categorical_accuracy: 0.3043\n",
      "Epoch 57/200\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2128 - categorical_accuracy: 0.3610 - val_loss: 2.6542 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2128 - categorical_accuracy: 0.3610 - val_loss: 2.6542 - val_categorical_accuracy: 0.3043\n",
      "Epoch 58/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.0740 - categorical_accuracy: 0.3600Epoch 58/200\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.1975 - categorical_accuracy: 0.3654 - val_loss: 2.6935 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.1975 - categorical_accuracy: 0.3654 - val_loss: 2.6935 - val_categorical_accuracy: 0.3023\n",
      "Epoch 59/200\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2039 - categorical_accuracy: 0.3626 - val_loss: 2.7245 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.2039 - categorical_accuracy: 0.3626 - val_loss: 2.7245 - val_categorical_accuracy: 0.3013\n",
      "Epoch 60/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.2076 - categorical_accuracy: 0.3700Epoch 60/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 2.2127 - categorical_accuracy: 0.3600 - val_loss: 2.6561 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 2.2127 - categorical_accuracy: 0.3600 - val_loss: 2.6561 - val_categorical_accuracy: 0.3043\n",
      "Epoch 61/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9964 - categorical_accuracy: 0.3600Epoch 61/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 2.2017 - categorical_accuracy: 0.3652 - val_loss: 2.6826 - val_categorical_accuracy: 0.3053\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 2.2017 - categorical_accuracy: 0.3652 - val_loss: 2.6826 - val_categorical_accuracy: 0.3053\n",
      "Epoch 62/200\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1819 - categorical_accuracy: 0.3710 - val_loss: 2.7029 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1819 - categorical_accuracy: 0.3710 - val_loss: 2.7029 - val_categorical_accuracy: 0.3013\n",
      "Epoch 63/200\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1610 - categorical_accuracy: 0.3668 - val_loss: 2.7314 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1610 - categorical_accuracy: 0.3668 - val_loss: 2.7314 - val_categorical_accuracy: 0.3023\n",
      "Epoch 64/200\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 2.1731 - categorical_accuracy: 0.3744 - val_loss: 2.6957 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 2.1731 - categorical_accuracy: 0.3744 - val_loss: 2.6957 - val_categorical_accuracy: 0.3023\n",
      "Epoch 65/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.0549 - categorical_accuracy: 0.4100Epoch 65/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.1578 - categorical_accuracy: 0.3724 - val_loss: 2.7200 - val_categorical_accuracy: 0.3003\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.1578 - categorical_accuracy: 0.3724 - val_loss: 2.7200 - val_categorical_accuracy: 0.3003\n",
      "Epoch 66/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.2438 - categorical_accuracy: 0.3800Epoch 66/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1582 - categorical_accuracy: 0.3726 - val_loss: 2.6819 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1582 - categorical_accuracy: 0.3726 - val_loss: 2.6819 - val_categorical_accuracy: 0.3043\n",
      "Epoch 67/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1087 - categorical_accuracy: 0.3500Epoch 67/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1361 - categorical_accuracy: 0.3826 - val_loss: 2.7070 - val_categorical_accuracy: 0.3003\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.1361 - categorical_accuracy: 0.3826 - val_loss: 2.7070 - val_categorical_accuracy: 0.3003\n",
      "Epoch 68/200\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1334 - categorical_accuracy: 0.3748 - val_loss: 2.7064 - val_categorical_accuracy: 0.2993\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1334 - categorical_accuracy: 0.3748 - val_loss: 2.7064 - val_categorical_accuracy: 0.2993\n",
      "Epoch 69/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9947 - categorical_accuracy: 0.3900Epoch 69/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1236 - categorical_accuracy: 0.3828 - val_loss: 2.7555 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1236 - categorical_accuracy: 0.3828 - val_loss: 2.7555 - val_categorical_accuracy: 0.3043\n",
      "Epoch 70/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9651 - categorical_accuracy: 0.4000Epoch 70/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1172 - categorical_accuracy: 0.3772 - val_loss: 2.7421 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1172 - categorical_accuracy: 0.3772 - val_loss: 2.7421 - val_categorical_accuracy: 0.3043\n",
      "Epoch 71/200\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1103 - categorical_accuracy: 0.3880 - val_loss: 2.7564 - val_categorical_accuracy: 0.2973\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1103 - categorical_accuracy: 0.3880 - val_loss: 2.7564 - val_categorical_accuracy: 0.2973\n",
      "Epoch 72/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.0758 - categorical_accuracy: 0.2900Epoch 72/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1110 - categorical_accuracy: 0.3832 - val_loss: 2.7537 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.1110 - categorical_accuracy: 0.3832 - val_loss: 2.7537 - val_categorical_accuracy: 0.3043\n",
      "Epoch 73/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.0229 - categorical_accuracy: 0.4000Epoch 73/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0940 - categorical_accuracy: 0.3882 - val_loss: 2.7317 - val_categorical_accuracy: 0.3033\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0940 - categorical_accuracy: 0.3882 - val_loss: 2.7317 - val_categorical_accuracy: 0.3033\n",
      "Epoch 74/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 2.0325 - categorical_accuracy: 0.3800Epoch 74/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.1030 - categorical_accuracy: 0.3746 - val_loss: 2.8375 - val_categorical_accuracy: 0.3013\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.1030 - categorical_accuracy: 0.3746 - val_loss: 2.8375 - val_categorical_accuracy: 0.3013\n",
      "Epoch 75/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9950 - categorical_accuracy: 0.4300Epoch 75/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0717 - categorical_accuracy: 0.3888 - val_loss: 2.8020 - val_categorical_accuracy: 0.2903\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0717 - categorical_accuracy: 0.3888 - val_loss: 2.8020 - val_categorical_accuracy: 0.2903\n",
      "Epoch 76/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.0537 - categorical_accuracy: 0.4300Epoch 76/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 2.0436 - categorical_accuracy: 0.3924 - val_loss: 2.8175 - val_categorical_accuracy: 0.2963\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 2.0436 - categorical_accuracy: 0.3924 - val_loss: 2.8175 - val_categorical_accuracy: 0.2963\n",
      "Epoch 77/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8967 - categorical_accuracy: 0.4100Epoch 77/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0581 - categorical_accuracy: 0.3962 - val_loss: 2.8568 - val_categorical_accuracy: 0.3053\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0581 - categorical_accuracy: 0.3962 - val_loss: 2.8568 - val_categorical_accuracy: 0.3053\n",
      "Epoch 78/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9751 - categorical_accuracy: 0.3900Epoch 78/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.0594 - categorical_accuracy: 0.3934 - val_loss: 2.8114 - val_categorical_accuracy: 0.2973\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.0594 - categorical_accuracy: 0.3934 - val_loss: 2.8114 - val_categorical_accuracy: 0.2973\n",
      "Epoch 79/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.0236 - categorical_accuracy: 0.4300Epoch 79/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0608 - categorical_accuracy: 0.3962 - val_loss: 2.8091 - val_categorical_accuracy: 0.3043\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0608 - categorical_accuracy: 0.3962 - val_loss: 2.8091 - val_categorical_accuracy: 0.3043\n",
      "Epoch 80/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9711 - categorical_accuracy: 0.4100Epoch 80/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.0392 - categorical_accuracy: 0.3970 - val_loss: 2.8613 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 2.0392 - categorical_accuracy: 0.3970 - val_loss: 2.8613 - val_categorical_accuracy: 0.3023\n",
      "Epoch 81/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9542 - categorical_accuracy: 0.4000Epoch 81/200\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.0547 - categorical_accuracy: 0.3964 - val_loss: 2.8526 - val_categorical_accuracy: 0.2883\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 2.0547 - categorical_accuracy: 0.3964 - val_loss: 2.8526 - val_categorical_accuracy: 0.2883\n",
      "Epoch 82/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9784 - categorical_accuracy: 0.3900Epoch 82/200\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 2.0340 - categorical_accuracy: 0.3940 - val_loss: 2.8658 - val_categorical_accuracy: 0.3033\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 2.0340 - categorical_accuracy: 0.3940 - val_loss: 2.8658 - val_categorical_accuracy: 0.3033\n",
      "Epoch 83/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9457 - categorical_accuracy: 0.4000Epoch 83/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0220 - categorical_accuracy: 0.4042 - val_loss: 2.8795 - val_categorical_accuracy: 0.2933\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.0220 - categorical_accuracy: 0.4042 - val_loss: 2.8795 - val_categorical_accuracy: 0.2933\n",
      "Epoch 84/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9658 - categorical_accuracy: 0.4000Epoch 84/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.0207 - categorical_accuracy: 0.4016 - val_loss: 2.8880 - val_categorical_accuracy: 0.2963\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 2.0207 - categorical_accuracy: 0.4016 - val_loss: 2.8880 - val_categorical_accuracy: 0.2963\n",
      "Epoch 85/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9582 - categorical_accuracy: 0.3900Epoch 85/200\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.9867 - categorical_accuracy: 0.4100 - val_loss: 2.7983 - val_categorical_accuracy: 0.3083\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.9867 - categorical_accuracy: 0.4100 - val_loss: 2.7983 - val_categorical_accuracy: 0.3083\n",
      "Epoch 86/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9862 - categorical_accuracy: 0.3900Epoch 86/200\n",
      "50/50 [==============================] - 3s 55ms/step - loss: 1.9899 - categorical_accuracy: 0.4054 - val_loss: 2.9417 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 3s 55ms/step - loss: 1.9899 - categorical_accuracy: 0.4054 - val_loss: 2.9417 - val_categorical_accuracy: 0.3023\n",
      "Epoch 87/200\n",
      " 1/50 [..............................] - ETA: 3s - loss: 1.9893 - categorical_accuracy: 0.4400Epoch 87/200\n",
      "50/50 [==============================] - 4s 70ms/step - loss: 1.9946 - categorical_accuracy: 0.4026 - val_loss: 2.8556 - val_categorical_accuracy: 0.3053\n",
      "50/50 [==============================] - 4s 70ms/step - loss: 1.9946 - categorical_accuracy: 0.4026 - val_loss: 2.8556 - val_categorical_accuracy: 0.3053\n",
      "Epoch 88/200\n",
      " 1/50 [..............................] - ETA: 3s - loss: 1.9381 - categorical_accuracy: 0.3800Epoch 88/200\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 1.9862 - categorical_accuracy: 0.4094 - val_loss: 2.9391 - val_categorical_accuracy: 0.3023\n",
      "50/50 [==============================] - 3s 69ms/step - loss: 1.9862 - categorical_accuracy: 0.4094 - val_loss: 2.9391 - val_categorical_accuracy: 0.3023\n",
      "Epoch 89/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9105 - categorical_accuracy: 0.4100Epoch 89/200\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 1.9656 - categorical_accuracy: 0.4156 - val_loss: 2.9309 - val_categorical_accuracy: 0.2973\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 1.9656 - categorical_accuracy: 0.4156 - val_loss: 2.9309 - val_categorical_accuracy: 0.2973\n",
      "Epoch 90/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9926 - categorical_accuracy: 0.4100Epoch 90/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9541 - categorical_accuracy: 0.4180 - val_loss: 2.9569 - val_categorical_accuracy: 0.2923\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9541 - categorical_accuracy: 0.4180 - val_loss: 2.9569 - val_categorical_accuracy: 0.2923\n",
      "Epoch 91/200\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9743 - categorical_accuracy: 0.4072 - val_loss: 2.9509 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9743 - categorical_accuracy: 0.4072 - val_loss: 2.9509 - val_categorical_accuracy: 0.2873\n",
      "Epoch 92/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9359 - categorical_accuracy: 0.4200Epoch 92/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9493 - categorical_accuracy: 0.4224 - val_loss: 3.0202 - val_categorical_accuracy: 0.2983\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9493 - categorical_accuracy: 0.4224 - val_loss: 3.0202 - val_categorical_accuracy: 0.2983\n",
      "Epoch 93/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9679 - categorical_accuracy: 0.4400Epoch 93/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9597 - categorical_accuracy: 0.4122 - val_loss: 2.9909 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9597 - categorical_accuracy: 0.4122 - val_loss: 2.9909 - val_categorical_accuracy: 0.2873\n",
      "Epoch 94/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9556 - categorical_accuracy: 0.4500Epoch 94/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9818 - categorical_accuracy: 0.4114 - val_loss: 3.0779 - val_categorical_accuracy: 0.2903\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9818 - categorical_accuracy: 0.4114 - val_loss: 3.0779 - val_categorical_accuracy: 0.2903\n",
      "Epoch 95/200\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9809 - categorical_accuracy: 0.4156 - val_loss: 2.9952 - val_categorical_accuracy: 0.2913\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9809 - categorical_accuracy: 0.4156 - val_loss: 2.9952 - val_categorical_accuracy: 0.2913\n",
      "Epoch 96/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8427 - categorical_accuracy: 0.4500Epoch 96/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9427 - categorical_accuracy: 0.4182 - val_loss: 3.0433 - val_categorical_accuracy: 0.2963\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9427 - categorical_accuracy: 0.4182 - val_loss: 3.0433 - val_categorical_accuracy: 0.2963\n",
      "Epoch 97/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 2.0061 - categorical_accuracy: 0.3900Epoch 97/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9191 - categorical_accuracy: 0.4244 - val_loss: 3.0647 - val_categorical_accuracy: 0.2913\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9191 - categorical_accuracy: 0.4244 - val_loss: 3.0647 - val_categorical_accuracy: 0.2913\n",
      "Epoch 98/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.9154 - categorical_accuracy: 0.4100Epoch 98/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9220 - categorical_accuracy: 0.4152 - val_loss: 3.0861 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9220 - categorical_accuracy: 0.4152 - val_loss: 3.0861 - val_categorical_accuracy: 0.2853\n",
      "Epoch 99/200\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9159 - categorical_accuracy: 0.4256 - val_loss: 3.1536 - val_categorical_accuracy: 0.2793\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9159 - categorical_accuracy: 0.4256 - val_loss: 3.1536 - val_categorical_accuracy: 0.2793\n",
      "Epoch 100/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8266 - categorical_accuracy: 0.3800Epoch 100/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9158 - categorical_accuracy: 0.4236 - val_loss: 3.0119 - val_categorical_accuracy: 0.2753\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9158 - categorical_accuracy: 0.4236 - val_loss: 3.0119 - val_categorical_accuracy: 0.2753\n",
      "Epoch 101/200\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9807 - categorical_accuracy: 0.4080 - val_loss: 3.0529 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.9807 - categorical_accuracy: 0.4080 - val_loss: 3.0529 - val_categorical_accuracy: 0.2853\n",
      "Epoch 102/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8894 - categorical_accuracy: 0.4500Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9281 - categorical_accuracy: 0.4258 - val_loss: 3.0600 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.9281 - categorical_accuracy: 0.4258 - val_loss: 3.0600 - val_categorical_accuracy: 0.2853\n",
      "Epoch 103/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7984 - categorical_accuracy: 0.4300Epoch 103/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8764 - categorical_accuracy: 0.4384 - val_loss: 3.1513 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8764 - categorical_accuracy: 0.4384 - val_loss: 3.1513 - val_categorical_accuracy: 0.2813\n",
      "Epoch 104/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8401 - categorical_accuracy: 0.4300Epoch 104/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8740 - categorical_accuracy: 0.4286 - val_loss: 3.1078 - val_categorical_accuracy: 0.2713\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8740 - categorical_accuracy: 0.4286 - val_loss: 3.1078 - val_categorical_accuracy: 0.2713\n",
      "Epoch 105/200\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8965 - categorical_accuracy: 0.4260 - val_loss: 3.0298 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8965 - categorical_accuracy: 0.4260 - val_loss: 3.0298 - val_categorical_accuracy: 0.2813\n",
      "Epoch 106/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.9610 - categorical_accuracy: 0.4200Epoch 106/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8816 - categorical_accuracy: 0.4360 - val_loss: 3.1456 - val_categorical_accuracy: 0.2903\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8816 - categorical_accuracy: 0.4360 - val_loss: 3.1456 - val_categorical_accuracy: 0.2903\n",
      "Epoch 107/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8906 - categorical_accuracy: 0.3600Epoch 107/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8813 - categorical_accuracy: 0.4330 - val_loss: 3.1347 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8813 - categorical_accuracy: 0.4330 - val_loss: 3.1347 - val_categorical_accuracy: 0.2843\n",
      "Epoch 108/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8737 - categorical_accuracy: 0.4400Epoch 108/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8697 - categorical_accuracy: 0.4340 - val_loss: 3.1246 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8697 - categorical_accuracy: 0.4340 - val_loss: 3.1246 - val_categorical_accuracy: 0.2813\n",
      "Epoch 109/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.8198 - categorical_accuracy: 0.4300Epoch 109/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8435 - categorical_accuracy: 0.4456 - val_loss: 3.2246 - val_categorical_accuracy: 0.2803\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8435 - categorical_accuracy: 0.4456 - val_loss: 3.2246 - val_categorical_accuracy: 0.2803\n",
      "Epoch 110/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.8533 - categorical_accuracy: 0.3900Epoch 110/200\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.8436 - categorical_accuracy: 0.4370 - val_loss: 3.1666 - val_categorical_accuracy: 0.2863\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.8436 - categorical_accuracy: 0.4370 - val_loss: 3.1666 - val_categorical_accuracy: 0.2863\n",
      "Epoch 111/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7305 - categorical_accuracy: 0.4600Epoch 111/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8620 - categorical_accuracy: 0.4426 - val_loss: 3.0836 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8620 - categorical_accuracy: 0.4426 - val_loss: 3.0836 - val_categorical_accuracy: 0.2813\n",
      "Epoch 112/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7314 - categorical_accuracy: 0.4400Epoch 112/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8955 - categorical_accuracy: 0.4236 - val_loss: 3.1474 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8955 - categorical_accuracy: 0.4236 - val_loss: 3.1474 - val_categorical_accuracy: 0.2873\n",
      "Epoch 113/200\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8369 - categorical_accuracy: 0.4380 - val_loss: 3.1457 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8369 - categorical_accuracy: 0.4380 - val_loss: 3.1457 - val_categorical_accuracy: 0.2873\n",
      "Epoch 114/200\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8334 - categorical_accuracy: 0.4414 - val_loss: 3.2723 - val_categorical_accuracy: 0.2763\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8334 - categorical_accuracy: 0.4414 - val_loss: 3.2723 - val_categorical_accuracy: 0.2763\n",
      "Epoch 115/200\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8046 - categorical_accuracy: 0.4540 - val_loss: 3.1890 - val_categorical_accuracy: 0.2803\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8046 - categorical_accuracy: 0.4540 - val_loss: 3.1890 - val_categorical_accuracy: 0.2803\n",
      "Epoch 116/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.8933 - categorical_accuracy: 0.3600Epoch 116/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8200 - categorical_accuracy: 0.4536 - val_loss: 3.2429 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8200 - categorical_accuracy: 0.4536 - val_loss: 3.2429 - val_categorical_accuracy: 0.2843\n",
      "Epoch 117/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7735 - categorical_accuracy: 0.4700Epoch 117/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8012 - categorical_accuracy: 0.4608 - val_loss: 3.2978 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.8012 - categorical_accuracy: 0.4608 - val_loss: 3.2978 - val_categorical_accuracy: 0.2813\n",
      "Epoch 118/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7303 - categorical_accuracy: 0.4600Epoch 118/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8194 - categorical_accuracy: 0.4482 - val_loss: 3.2371 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8194 - categorical_accuracy: 0.4482 - val_loss: 3.2371 - val_categorical_accuracy: 0.2813\n",
      "Epoch 119/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7805 - categorical_accuracy: 0.4700Epoch 119/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7964 - categorical_accuracy: 0.4538 - val_loss: 3.2278 - val_categorical_accuracy: 0.2953\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7964 - categorical_accuracy: 0.4538 - val_loss: 3.2278 - val_categorical_accuracy: 0.2953\n",
      "Epoch 120/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8262 - categorical_accuracy: 0.4000Epoch 120/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7865 - categorical_accuracy: 0.4576 - val_loss: 3.3250 - val_categorical_accuracy: 0.2793\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7865 - categorical_accuracy: 0.4576 - val_loss: 3.3250 - val_categorical_accuracy: 0.2793\n",
      "Epoch 121/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.8897 - categorical_accuracy: 0.4600Epoch 121/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8318 - categorical_accuracy: 0.4362 - val_loss: 3.2205 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8318 - categorical_accuracy: 0.4362 - val_loss: 3.2205 - val_categorical_accuracy: 0.2853\n",
      "Epoch 122/200\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8626 - categorical_accuracy: 0.4432 - val_loss: 3.1223 - val_categorical_accuracy: 0.2923\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8626 - categorical_accuracy: 0.4432 - val_loss: 3.1223 - val_categorical_accuracy: 0.2923\n",
      "Epoch 123/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8189 - categorical_accuracy: 0.4400Epoch 123/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7851 - categorical_accuracy: 0.4560 - val_loss: 3.2225 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7851 - categorical_accuracy: 0.4560 - val_loss: 3.2225 - val_categorical_accuracy: 0.2853\n",
      "Epoch 124/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8207 - categorical_accuracy: 0.4100Epoch 124/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7926 - categorical_accuracy: 0.4526 - val_loss: 3.2352 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7926 - categorical_accuracy: 0.4526 - val_loss: 3.2352 - val_categorical_accuracy: 0.2873\n",
      "Epoch 125/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.8793 - categorical_accuracy: 0.4600Epoch 125/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7710 - categorical_accuracy: 0.4568 - val_loss: 3.2887 - val_categorical_accuracy: 0.2883\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7710 - categorical_accuracy: 0.4568 - val_loss: 3.2887 - val_categorical_accuracy: 0.2883\n",
      "Epoch 126/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6738 - categorical_accuracy: 0.4700Epoch 126/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7482 - categorical_accuracy: 0.4682 - val_loss: 3.3327 - val_categorical_accuracy: 0.2953\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7482 - categorical_accuracy: 0.4682 - val_loss: 3.3327 - val_categorical_accuracy: 0.2953\n",
      "Epoch 127/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6937 - categorical_accuracy: 0.4500Epoch 127/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7404 - categorical_accuracy: 0.4632 - val_loss: 3.3175 - val_categorical_accuracy: 0.2943\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7404 - categorical_accuracy: 0.4632 - val_loss: 3.3175 - val_categorical_accuracy: 0.2943\n",
      "Epoch 128/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.5683 - categorical_accuracy: 0.5000Epoch 128/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7448 - categorical_accuracy: 0.4702 - val_loss: 3.3562 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7448 - categorical_accuracy: 0.4702 - val_loss: 3.3562 - val_categorical_accuracy: 0.2843\n",
      "Epoch 129/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7006 - categorical_accuracy: 0.4700Epoch 129/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9528 - categorical_accuracy: 0.4104 - val_loss: 3.0306 - val_categorical_accuracy: 0.2593\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9528 - categorical_accuracy: 0.4104 - val_loss: 3.0306 - val_categorical_accuracy: 0.2593\n",
      "Epoch 130/200\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8941 - categorical_accuracy: 0.4254 - val_loss: 3.0753 - val_categorical_accuracy: 0.2673\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.8941 - categorical_accuracy: 0.4254 - val_loss: 3.0753 - val_categorical_accuracy: 0.2673\n",
      "Epoch 131/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7378 - categorical_accuracy: 0.4500Epoch 131/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8637 - categorical_accuracy: 0.4424 - val_loss: 3.1280 - val_categorical_accuracy: 0.2663\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.8637 - categorical_accuracy: 0.4424 - val_loss: 3.1280 - val_categorical_accuracy: 0.2663\n",
      "Epoch 132/200\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.8250 - categorical_accuracy: 0.4548 - val_loss: 3.1159 - val_categorical_accuracy: 0.2763\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 1.8250 - categorical_accuracy: 0.4548 - val_loss: 3.1159 - val_categorical_accuracy: 0.2763\n",
      "Epoch 133/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7781 - categorical_accuracy: 0.4300Epoch 133/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7692 - categorical_accuracy: 0.4530 - val_loss: 3.1701 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7692 - categorical_accuracy: 0.4530 - val_loss: 3.1701 - val_categorical_accuracy: 0.2813\n",
      "Epoch 134/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5426 - categorical_accuracy: 0.5500Epoch 134/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7534 - categorical_accuracy: 0.4646 - val_loss: 3.1775 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7534 - categorical_accuracy: 0.4646 - val_loss: 3.1775 - val_categorical_accuracy: 0.2843\n",
      "Epoch 135/200\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 4s 76ms/step - loss: 1.7618 - categorical_accuracy: 0.4628 - val_loss: 3.2276 - val_categorical_accuracy: 0.2823\n",
      "50/50 [==============================] - 4s 76ms/step - loss: 1.7618 - categorical_accuracy: 0.4628 - val_loss: 3.2276 - val_categorical_accuracy: 0.2823\n",
      "Epoch 136/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7349 - categorical_accuracy: 0.4700Epoch 136/200\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 1.7336 - categorical_accuracy: 0.4768 - val_loss: 3.2409 - val_categorical_accuracy: 0.2743\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 1.7336 - categorical_accuracy: 0.4768 - val_loss: 3.2409 - val_categorical_accuracy: 0.2743\n",
      "Epoch 137/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6587 - categorical_accuracy: 0.5300Epoch 137/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7303 - categorical_accuracy: 0.4644 - val_loss: 3.2646 - val_categorical_accuracy: 0.2783\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7303 - categorical_accuracy: 0.4644 - val_loss: 3.2646 - val_categorical_accuracy: 0.2783\n",
      "Epoch 138/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.6575 - categorical_accuracy: 0.4600Epoch 138/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7445 - categorical_accuracy: 0.4684 - val_loss: 3.2603 - val_categorical_accuracy: 0.2773\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.7445 - categorical_accuracy: 0.4684 - val_loss: 3.2603 - val_categorical_accuracy: 0.2773\n",
      "Epoch 139/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.6305 - categorical_accuracy: 0.5100Epoch 139/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6980 - categorical_accuracy: 0.4862 - val_loss: 3.3104 - val_categorical_accuracy: 0.2793\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6980 - categorical_accuracy: 0.4862 - val_loss: 3.3104 - val_categorical_accuracy: 0.2793\n",
      "Epoch 140/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6949 - categorical_accuracy: 0.5000Epoch 140/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6898 - categorical_accuracy: 0.4850 - val_loss: 3.3285 - val_categorical_accuracy: 0.2763\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6898 - categorical_accuracy: 0.4850 - val_loss: 3.3285 - val_categorical_accuracy: 0.2763\n",
      "Epoch 141/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.6126 - categorical_accuracy: 0.4800Epoch 141/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.7604 - categorical_accuracy: 0.4626 - val_loss: 3.2741 - val_categorical_accuracy: 0.2783\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.7604 - categorical_accuracy: 0.4626 - val_loss: 3.2741 - val_categorical_accuracy: 0.2783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.5905 - categorical_accuracy: 0.4900Epoch 142/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7266 - categorical_accuracy: 0.4734 - val_loss: 3.3675 - val_categorical_accuracy: 0.2773\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.7266 - categorical_accuracy: 0.4734 - val_loss: 3.3675 - val_categorical_accuracy: 0.2773\n",
      "Epoch 143/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7128 - categorical_accuracy: 0.4900Epoch 143/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6948 - categorical_accuracy: 0.4792 - val_loss: 3.3508 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6948 - categorical_accuracy: 0.4792 - val_loss: 3.3508 - val_categorical_accuracy: 0.2853\n",
      "Epoch 144/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6646 - categorical_accuracy: 0.5000Epoch 144/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6710 - categorical_accuracy: 0.4946 - val_loss: 3.3767 - val_categorical_accuracy: 0.2703\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6710 - categorical_accuracy: 0.4946 - val_loss: 3.3767 - val_categorical_accuracy: 0.2703\n",
      "Epoch 145/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.5810 - categorical_accuracy: 0.4800Epoch 145/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6848 - categorical_accuracy: 0.4840 - val_loss: 3.3454 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6848 - categorical_accuracy: 0.4840 - val_loss: 3.3454 - val_categorical_accuracy: 0.2853\n",
      "Epoch 146/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7918 - categorical_accuracy: 0.4500Epoch 146/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7056 - categorical_accuracy: 0.4772 - val_loss: 3.3709 - val_categorical_accuracy: 0.2873\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.7056 - categorical_accuracy: 0.4772 - val_loss: 3.3709 - val_categorical_accuracy: 0.2873\n",
      "Epoch 147/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6627 - categorical_accuracy: 0.4600Epoch 147/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6789 - categorical_accuracy: 0.4866 - val_loss: 3.3163 - val_categorical_accuracy: 0.2833\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6789 - categorical_accuracy: 0.4866 - val_loss: 3.3163 - val_categorical_accuracy: 0.2833\n",
      "Epoch 148/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.6251 - categorical_accuracy: 0.5100Epoch 148/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6773 - categorical_accuracy: 0.4874 - val_loss: 3.3155 - val_categorical_accuracy: 0.2783\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6773 - categorical_accuracy: 0.4874 - val_loss: 3.3155 - val_categorical_accuracy: 0.2783\n",
      "Epoch 149/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7525 - categorical_accuracy: 0.4600Epoch 149/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6768 - categorical_accuracy: 0.4838 - val_loss: 3.3471 - val_categorical_accuracy: 0.2753\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6768 - categorical_accuracy: 0.4838 - val_loss: 3.3471 - val_categorical_accuracy: 0.2753\n",
      "Epoch 150/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6002 - categorical_accuracy: 0.4700Epoch 150/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6422 - categorical_accuracy: 0.4952 - val_loss: 3.4262 - val_categorical_accuracy: 0.2613\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6422 - categorical_accuracy: 0.4952 - val_loss: 3.4262 - val_categorical_accuracy: 0.2613\n",
      "Epoch 151/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.7201 - categorical_accuracy: 0.4500Epoch 151/200\n",
      "50/50 [==============================] - 2s 50ms/step - loss: 1.6599 - categorical_accuracy: 0.4802 - val_loss: 3.3634 - val_categorical_accuracy: 0.2823\n",
      "50/50 [==============================] - 2s 50ms/step - loss: 1.6599 - categorical_accuracy: 0.4802 - val_loss: 3.3634 - val_categorical_accuracy: 0.2823\n",
      "Epoch 152/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5045 - categorical_accuracy: 0.5600Epoch 152/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6344 - categorical_accuracy: 0.4994 - val_loss: 3.4900 - val_categorical_accuracy: 0.2663\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6344 - categorical_accuracy: 0.4994 - val_loss: 3.4900 - val_categorical_accuracy: 0.2663\n",
      "Epoch 153/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6962 - categorical_accuracy: 0.4300Epoch 153/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6471 - categorical_accuracy: 0.4982 - val_loss: 3.5022 - val_categorical_accuracy: 0.2623\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6471 - categorical_accuracy: 0.4982 - val_loss: 3.5022 - val_categorical_accuracy: 0.2623\n",
      "Epoch 154/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.6464 - categorical_accuracy: 0.4700Epoch 154/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6657 - categorical_accuracy: 0.4952 - val_loss: 3.3958 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6657 - categorical_accuracy: 0.4952 - val_loss: 3.3958 - val_categorical_accuracy: 0.2853\n",
      "Epoch 155/200\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6276 - categorical_accuracy: 0.4940 - val_loss: 3.4029 - val_categorical_accuracy: 0.2823\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6276 - categorical_accuracy: 0.4940 - val_loss: 3.4029 - val_categorical_accuracy: 0.2823\n",
      "Epoch 156/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.5920 - categorical_accuracy: 0.5400Epoch 156/200\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6022 - categorical_accuracy: 0.5094 - val_loss: 3.5273 - val_categorical_accuracy: 0.2713\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.6022 - categorical_accuracy: 0.5094 - val_loss: 3.5273 - val_categorical_accuracy: 0.2713\n",
      "Epoch 157/200\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6361 - categorical_accuracy: 0.4984 - val_loss: 3.4273 - val_categorical_accuracy: 0.2733\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6361 - categorical_accuracy: 0.4984 - val_loss: 3.4273 - val_categorical_accuracy: 0.2733\n",
      "Epoch 158/200\n",
      " 1/50 [..............................] - ETA: 2s - loss: 1.4892 - categorical_accuracy: 0.5600Epoch 158/200\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6198 - categorical_accuracy: 0.4974 - val_loss: 3.5155 - val_categorical_accuracy: 0.2593\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 1.6198 - categorical_accuracy: 0.4974 - val_loss: 3.5155 - val_categorical_accuracy: 0.2593\n",
      "Epoch 159/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5614 - categorical_accuracy: 0.5400Epoch 159/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6521 - categorical_accuracy: 0.4962 - val_loss: 3.4474 - val_categorical_accuracy: 0.2553\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6521 - categorical_accuracy: 0.4962 - val_loss: 3.4474 - val_categorical_accuracy: 0.2553\n",
      "Epoch 160/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7401 - categorical_accuracy: 0.4200Epoch 160/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7132 - categorical_accuracy: 0.4860 - val_loss: 3.4280 - val_categorical_accuracy: 0.2713\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7132 - categorical_accuracy: 0.4860 - val_loss: 3.4280 - val_categorical_accuracy: 0.2713\n",
      "Epoch 161/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5725 - categorical_accuracy: 0.4800Epoch 161/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6734 - categorical_accuracy: 0.4826 - val_loss: 3.4476 - val_categorical_accuracy: 0.2723\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6734 - categorical_accuracy: 0.4826 - val_loss: 3.4476 - val_categorical_accuracy: 0.2723\n",
      "Epoch 162/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6190 - categorical_accuracy: 0.4800Epoch 162/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6695 - categorical_accuracy: 0.4872 - val_loss: 3.4614 - val_categorical_accuracy: 0.2763\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6695 - categorical_accuracy: 0.4872 - val_loss: 3.4614 - val_categorical_accuracy: 0.2763\n",
      "Epoch 163/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8004 - categorical_accuracy: 0.4400Epoch 163/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6423 - categorical_accuracy: 0.4990 - val_loss: 3.4725 - val_categorical_accuracy: 0.2503\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6423 - categorical_accuracy: 0.4990 - val_loss: 3.4725 - val_categorical_accuracy: 0.2503\n",
      "Epoch 164/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6558 - categorical_accuracy: 0.4400Epoch 164/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6599 - categorical_accuracy: 0.4870 - val_loss: 3.4618 - val_categorical_accuracy: 0.2553\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6599 - categorical_accuracy: 0.4870 - val_loss: 3.4618 - val_categorical_accuracy: 0.2553\n",
      "Epoch 165/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6100 - categorical_accuracy: 0.5300Epoch 165/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7352 - categorical_accuracy: 0.4742 - val_loss: 3.2065 - val_categorical_accuracy: 0.2472\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7352 - categorical_accuracy: 0.4742 - val_loss: 3.2065 - val_categorical_accuracy: 0.2472\n",
      "Epoch 166/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7040 - categorical_accuracy: 0.4500Epoch 166/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7064 - categorical_accuracy: 0.4774 - val_loss: 3.3700 - val_categorical_accuracy: 0.2653\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7064 - categorical_accuracy: 0.4774 - val_loss: 3.3700 - val_categorical_accuracy: 0.2653\n",
      "Epoch 167/200\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7102 - categorical_accuracy: 0.4778 - val_loss: 3.2572 - val_categorical_accuracy: 0.2633\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7102 - categorical_accuracy: 0.4778 - val_loss: 3.2572 - val_categorical_accuracy: 0.2633\n",
      "Epoch 168/200\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6658 - categorical_accuracy: 0.4870 - val_loss: 3.2814 - val_categorical_accuracy: 0.2713\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6658 - categorical_accuracy: 0.4870 - val_loss: 3.2814 - val_categorical_accuracy: 0.2713\n",
      "Epoch 169/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7859 - categorical_accuracy: 0.5100Epoch 169/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6610 - categorical_accuracy: 0.4960 - val_loss: 3.3188 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6610 - categorical_accuracy: 0.4960 - val_loss: 3.3188 - val_categorical_accuracy: 0.2843\n",
      "Epoch 170/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7261 - categorical_accuracy: 0.4700Epoch 170/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6642 - categorical_accuracy: 0.4836 - val_loss: 3.3963 - val_categorical_accuracy: 0.2492\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6642 - categorical_accuracy: 0.4836 - val_loss: 3.3963 - val_categorical_accuracy: 0.2492\n",
      "Epoch 171/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.8768 - categorical_accuracy: 0.4900Epoch 171/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7138 - categorical_accuracy: 0.4830 - val_loss: 3.2740 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.7138 - categorical_accuracy: 0.4830 - val_loss: 3.2740 - val_categorical_accuracy: 0.2813\n",
      "Epoch 172/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.7139 - categorical_accuracy: 0.5000Epoch 172/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6503 - categorical_accuracy: 0.4898 - val_loss: 3.3309 - val_categorical_accuracy: 0.2853\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6503 - categorical_accuracy: 0.4898 - val_loss: 3.3309 - val_categorical_accuracy: 0.2853\n",
      "Epoch 173/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5542 - categorical_accuracy: 0.5300Epoch 173/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6478 - categorical_accuracy: 0.4860 - val_loss: 3.2666 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6478 - categorical_accuracy: 0.4860 - val_loss: 3.2666 - val_categorical_accuracy: 0.2813\n",
      "Epoch 174/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6253 - categorical_accuracy: 0.5000Epoch 174/200\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6105 - categorical_accuracy: 0.4988 - val_loss: 3.3558 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 1.6105 - categorical_accuracy: 0.4988 - val_loss: 3.3558 - val_categorical_accuracy: 0.2843\n",
      "Epoch 175/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5403 - categorical_accuracy: 0.4300Epoch 175/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5741 - categorical_accuracy: 0.5158 - val_loss: 3.4015 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5741 - categorical_accuracy: 0.5158 - val_loss: 3.4015 - val_categorical_accuracy: 0.2843\n",
      "Epoch 176/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5741 - categorical_accuracy: 0.4900Epoch 176/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6041 - categorical_accuracy: 0.5034 - val_loss: 3.4048 - val_categorical_accuracy: 0.2673\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6041 - categorical_accuracy: 0.5034 - val_loss: 3.4048 - val_categorical_accuracy: 0.2673\n",
      "Epoch 177/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6309 - categorical_accuracy: 0.4400Epoch 177/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5843 - categorical_accuracy: 0.5040 - val_loss: 3.4087 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5843 - categorical_accuracy: 0.5040 - val_loss: 3.4087 - val_categorical_accuracy: 0.2843\n",
      "Epoch 178/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5652 - categorical_accuracy: 0.4500Epoch 178/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5753 - categorical_accuracy: 0.5124 - val_loss: 3.4359 - val_categorical_accuracy: 0.2773\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5753 - categorical_accuracy: 0.5124 - val_loss: 3.4359 - val_categorical_accuracy: 0.2773\n",
      "Epoch 179/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5184 - categorical_accuracy: 0.5600Epoch 179/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6008 - categorical_accuracy: 0.5056 - val_loss: 3.4507 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.6008 - categorical_accuracy: 0.5056 - val_loss: 3.4507 - val_categorical_accuracy: 0.2813\n",
      "Epoch 180/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5658 - categorical_accuracy: 0.5100Epoch 180/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5839 - categorical_accuracy: 0.5084 - val_loss: 3.4177 - val_categorical_accuracy: 0.2733\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5839 - categorical_accuracy: 0.5084 - val_loss: 3.4177 - val_categorical_accuracy: 0.2733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5150 - categorical_accuracy: 0.5300Epoch 181/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5518 - categorical_accuracy: 0.5154 - val_loss: 3.4167 - val_categorical_accuracy: 0.2813\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5518 - categorical_accuracy: 0.5154 - val_loss: 3.4167 - val_categorical_accuracy: 0.2813\n",
      "Epoch 182/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5695 - categorical_accuracy: 0.5600Epoch 182/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5416 - categorical_accuracy: 0.5284 - val_loss: 3.4712 - val_categorical_accuracy: 0.2773\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5416 - categorical_accuracy: 0.5284 - val_loss: 3.4712 - val_categorical_accuracy: 0.2773\n",
      "Epoch 183/200\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5309 - categorical_accuracy: 0.5254 - val_loss: 3.5274 - val_categorical_accuracy: 0.2663\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5309 - categorical_accuracy: 0.5254 - val_loss: 3.5274 - val_categorical_accuracy: 0.2663\n",
      "Epoch 184/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5243 - categorical_accuracy: 0.5200Epoch 184/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5508 - categorical_accuracy: 0.5150 - val_loss: 3.4435 - val_categorical_accuracy: 0.2743\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5508 - categorical_accuracy: 0.5150 - val_loss: 3.4435 - val_categorical_accuracy: 0.2743\n",
      "Epoch 185/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4249 - categorical_accuracy: 0.5800Epoch 185/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5157 - categorical_accuracy: 0.5352 - val_loss: 3.6141 - val_categorical_accuracy: 0.2843\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5157 - categorical_accuracy: 0.5352 - val_loss: 3.6141 - val_categorical_accuracy: 0.2843\n",
      "Epoch 186/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5252 - categorical_accuracy: 0.5100Epoch 186/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5036 - categorical_accuracy: 0.5312 - val_loss: 3.6323 - val_categorical_accuracy: 0.2793\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5036 - categorical_accuracy: 0.5312 - val_loss: 3.6323 - val_categorical_accuracy: 0.2793\n",
      "Epoch 187/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.3496 - categorical_accuracy: 0.6000Epoch 187/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5032 - categorical_accuracy: 0.5374 - val_loss: 3.5944 - val_categorical_accuracy: 0.2743\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5032 - categorical_accuracy: 0.5374 - val_loss: 3.5944 - val_categorical_accuracy: 0.2743\n",
      "Epoch 188/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5613 - categorical_accuracy: 0.4900Epoch 188/200\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.5103 - categorical_accuracy: 0.5298 - val_loss: 3.5599 - val_categorical_accuracy: 0.2803\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.5103 - categorical_accuracy: 0.5298 - val_loss: 3.5599 - val_categorical_accuracy: 0.2803\n",
      "Epoch 189/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.6396 - categorical_accuracy: 0.4500Epoch 189/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4909 - categorical_accuracy: 0.5328 - val_loss: 3.5399 - val_categorical_accuracy: 0.2823\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4909 - categorical_accuracy: 0.5328 - val_loss: 3.5399 - val_categorical_accuracy: 0.2823\n",
      "Epoch 190/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5560 - categorical_accuracy: 0.5500Epoch 190/200\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.4991 - categorical_accuracy: 0.5352 - val_loss: 3.6520 - val_categorical_accuracy: 0.2683\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.4991 - categorical_accuracy: 0.5352 - val_loss: 3.6520 - val_categorical_accuracy: 0.2683\n",
      "Epoch 191/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5143 - categorical_accuracy: 0.5400Epoch 191/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5531 - categorical_accuracy: 0.5174 - val_loss: 3.5804 - val_categorical_accuracy: 0.2713\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5531 - categorical_accuracy: 0.5174 - val_loss: 3.5804 - val_categorical_accuracy: 0.2713\n",
      "Epoch 192/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4695 - categorical_accuracy: 0.5400Epoch 192/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5648 - categorical_accuracy: 0.5116 - val_loss: 3.6477 - val_categorical_accuracy: 0.2743\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5648 - categorical_accuracy: 0.5116 - val_loss: 3.6477 - val_categorical_accuracy: 0.2743\n",
      "Epoch 193/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.5031 - categorical_accuracy: 0.5000Epoch 193/200\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.4851 - categorical_accuracy: 0.5326 - val_loss: 3.5825 - val_categorical_accuracy: 0.2793\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.4851 - categorical_accuracy: 0.5326 - val_loss: 3.5825 - val_categorical_accuracy: 0.2793\n",
      "Epoch 194/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4586 - categorical_accuracy: 0.5000Epoch 194/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4818 - categorical_accuracy: 0.5354 - val_loss: 3.6622 - val_categorical_accuracy: 0.2643\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4818 - categorical_accuracy: 0.5354 - val_loss: 3.6622 - val_categorical_accuracy: 0.2643\n",
      "Epoch 195/200\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5022 - categorical_accuracy: 0.5302 - val_loss: 3.5238 - val_categorical_accuracy: 0.2703\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.5022 - categorical_accuracy: 0.5302 - val_loss: 3.5238 - val_categorical_accuracy: 0.2703\n",
      "Epoch 196/200\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4941 - categorical_accuracy: 0.5394 - val_loss: 3.6685 - val_categorical_accuracy: 0.2743\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4941 - categorical_accuracy: 0.5394 - val_loss: 3.6685 - val_categorical_accuracy: 0.2743\n",
      "Epoch 197/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4974 - categorical_accuracy: 0.5300Epoch 197/200\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.5180 - categorical_accuracy: 0.5268 - val_loss: 3.6422 - val_categorical_accuracy: 0.2633\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 1.5180 - categorical_accuracy: 0.5268 - val_loss: 3.6422 - val_categorical_accuracy: 0.2633\n",
      "Epoch 198/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4073 - categorical_accuracy: 0.5200Epoch 198/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4722 - categorical_accuracy: 0.5388 - val_loss: 3.7313 - val_categorical_accuracy: 0.2673\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4722 - categorical_accuracy: 0.5388 - val_loss: 3.7313 - val_categorical_accuracy: 0.2673\n",
      "Epoch 199/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.4783 - categorical_accuracy: 0.5000Epoch 199/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4747 - categorical_accuracy: 0.5418 - val_loss: 3.6332 - val_categorical_accuracy: 0.2613\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4747 - categorical_accuracy: 0.5418 - val_loss: 3.6332 - val_categorical_accuracy: 0.2613\n",
      "Epoch 200/200\n",
      " 1/50 [..............................] - ETA: 1s - loss: 1.3275 - categorical_accuracy: 0.5900Epoch 200/200\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4357 - categorical_accuracy: 0.5470 - val_loss: 3.7746 - val_categorical_accuracy: 0.2553\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 1.4357 - categorical_accuracy: 0.5470 - val_loss: 3.7746 - val_categorical_accuracy: 0.2553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e6db8cbe0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e6db8cbe0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_batches = MagnitudeUtils.batchify(x_train, y_train, BATCH_SIZE) # Split the training data into batches\n",
    "num_batches_per_epoch_train = int(np.ceil(num_training/float(BATCH_SIZE)))\n",
    "test_batches = MagnitudeUtils.batchify(x_test, y_test, BATCH_SIZE)  # Split the test data into batches\n",
    "num_batches_per_epoch_test = int(np.ceil(num_test/float(BATCH_SIZE)))\n",
    "\n",
    "# Generates batches of the transformed training data\n",
    "train_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_train_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_train_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_train_batch, y_train_batch in training_batches\n",
    ")\n",
    "\n",
    "# Generates batches of the transformed test data\n",
    "test_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_test_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_test_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_test_batch, y_test_batch in test_batches\n",
    ")\n",
    "\n",
    "# Start training\n",
    "from keras.utils import np_utils\n",
    "model.fit_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps_per_epoch = num_batches_per_epoch_train,\n",
    "    validation_data = test_batch_generator,\n",
    "    validation_steps = num_batches_per_epoch_test,\n",
    "    epochs = EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after training for 200 epochs:\n",
      "loss: 1.1604 - categorical_accuracy: 0.6434\n",
      "val_loss: 3.7746 - val_categorical_accuracy: 0.2553\n"
     ]
    }
   ],
   "source": [
    "print(\"Results after training for %d epochs:\" % (EPOCHS,))\n",
    "\n",
    "train_metrics = model.evaluate_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps = num_batches_per_epoch_train,\n",
    ")\n",
    "\n",
    "print(\"loss: %.4f - categorical_accuracy: %.4f\" % tuple(train_metrics))\n",
    "\n",
    "val_metrics = model.evaluate_generator(\n",
    "    generator = test_batch_generator,\n",
    "    steps = num_batches_per_epoch_test,\n",
    ")\n",
    "\n",
    "print(\"val_loss: %.4f - val_categorical_accuracy: %.4f\" % tuple(val_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bariatrics\n"
     ]
    }
   ],
   "source": [
    "print(int_to_intent(MagnitudeUtils.from_categorical(model.predict(med_vectors.query([\"past medical history difficulty climbing stairs difficulty airline seats tying shoes used public seating lifting objects floor\".split(\" \")])))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ehr_sentences.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['Specialty', 'Note'])\n",
    "    for sent in ehr_sentences:\n",
    "        writer.writerow(sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_labels = []\n",
    "ehr_vectors = []\n",
    "\n",
    "for sentence in ehr_sentences:\n",
    "    ehr_labels.append(sentence[0])\n",
    "\n",
    "    sentence_split = sentence[1].split(' ')\n",
    "    ehr_vectors.append(med_vectors.query(sentence_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ehr_labels.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['SpecialtyID'])\n",
    "    for lbl in ehr_labels:\n",
    "        writer.writerow(lbl)\n",
    "        \n",
    "with open('data/ehr_vectors.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['NoteVector'])\n",
    "    for vctr in ehr_vectors:\n",
    "        writer.writerow(vctr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
