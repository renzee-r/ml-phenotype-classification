{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/renzeer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time, wget, csv, string, time, random\n",
    "import itertools, collections\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GaussianNoise, Dropout, Dense, Embedding, MaxPool1D, GlobalMaxPool1D, Conv1D, LSTM, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier for Cardiovascular Disease using a Convolutional Neural Network\n",
    "\n",
    "In this notebook, we will be building a model for classifying a sentence from an EHR note for the presence of cardiovascular disease. The model will be trained using a convoultional neural network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other', 'PAST MEDICAL HISTORY:, He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, and lifting objects off the floor.  He exercises three times a week at home and does cardio.  He has difficulty walking two blocks or five flights of stairs.  Difficulty with snoring.  He has muscle and joint pains including knee pain, back pain, foot and ankle pain, and swelling.  He has gastroesophageal reflux disease.,PAST SURGICAL HISTORY:, Includes reconstructive surgery on his right hand 13 years ago.  ,SOCIAL HISTORY:, He is currently single.  He has about ten drinks a year.  He had smoked significantly up until several months ago.  He now smokes less than three cigarettes a day.,FAMILY HISTORY:, Heart disease in both grandfathers, grandmother with stroke, and a grandmother with diabetes.  Denies obesity and hypertension in other family members.,CURRENT MEDICATIONS:, None.,ALLERGIES:,  He is allergic to Penicillin.,MISCELLANEOUS/EATING HISTORY:, He has been going to support groups for seven months with Lynn Holmberg in Greenwich and he is from Eastchester, New York and he feels that we are the appropriate program.  He had a poor experience with the Greenwich program.  Eating history, he is not an emotional eater.  Does not like sweets.  He likes big portions and carbohydrates.  He likes chicken and not steak.  He currently weighs 312 pounds.  Ideal body weight would be 170 pounds.  He is 142 pounds overweight.  If ,he lost 60% of his excess body weight that would be 84 pounds and he should weigh about 228.,REVIEW OF SYSTEMS: ,Negative for head, neck, heart, lungs, GI, GU, orthopedic, and skin.  Specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, CVA, venous insufficiency, thrombophlebitis, asthma, shortness of breath, COPD, emphysema, sleep apnea, diabetes, leg and foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  Denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:, He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Afebrile.  Vital Signs are stable.']\n",
      "['Cardiovascular', '2-D M-MODE: , ,1.  Left atrial enlargement with left atrial diameter of 4.7 cm.,2.  Normal size right and left ventricle.,3.  Normal LV systolic function with left ventricular ejection fraction of 51%.,4.  Normal LV diastolic function.,5.  No pericardial effusion.,6.  Normal morphology of aortic valve, mitral valve, tricuspid valve, and pulmonary valve.,7.  PA systolic pressure is 36 mmHg.,DOPPLER: , ,1.  Mild mitral and tricuspid regurgitation.,2.  Trace aortic and pulmonary regurgitation.']\n"
     ]
    }
   ],
   "source": [
    "ehr_notes = []\n",
    "with open('data/ehr_samples.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:     \n",
    "        if int(row['SpecialtyID']) in [39, 6, 16, 37, 11, 12, 29, 26, 7, 21, 19, 10, 2, 18]:\n",
    "            continue\n",
    "        elif int(row['SpecialtyID']) != 4:\n",
    "            ehr_notes.append(['Other', row['Note']])\n",
    "        else:\n",
    "            ehr_notes.append([row['Specialty'], row['Note']])\n",
    "\n",
    "print(ehr_notes[0])\n",
    "print(ehr_notes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Langauge Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular', 'return clinic 4 weeks5']\n",
      "['Other', 'biceps tendon nonsubluxable']\n"
     ]
    }
   ],
   "source": [
    "ehr_sentences = []\n",
    "for record in ehr_notes:\n",
    "    sent_text = nltk.sent_tokenize(record[1])\n",
    "    for sent in sent_text:\n",
    "        tokens = word_tokenize(sent)\n",
    "\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "        # filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "#         # stem words\n",
    "#         porter = PorterStemmer()\n",
    "#         tokens = [porter.stem(word) for word in tokens]\n",
    "\n",
    "        # remove blanks\n",
    "        tokens = [w for w in tokens if w != '']\n",
    "\n",
    "        ehr_sentences.append([record[0], ' '.join(tokens)])\n",
    "\n",
    "random.Random(4).shuffle(ehr_sentences)\n",
    "\n",
    "print(ehr_sentences[0])\n",
    "print(ehr_sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "\n",
    "The first step is to load in our word embedding, which is trained on text from Wikipedia, Pubmed, and Pubmed Central. We load our word embedding through a tool called Magnitude. A full exploration of the word embedding and Magnitude can be found in the Introduction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = list(np.array(ehr_sentences)[:,1])\n",
    "lengths = [len(note.split(' ')) for note in notes]\n",
    "MAX_WORDS = max(lengths) # The maximum number of words the sequence model will consider\n",
    "med_vectors = Magnitude(\"data/wikipedia-pubmed-and-PMC-w2v.magnitude\", pad_to_length=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Training and Test Data\n",
    "\n",
    "Before we can start building our neural networks, we first have to define our datasets. Specifically, we have to break up our EHR data so that we have records that we can train on and records that are exclusively used to test on. Maintaining a separate set for testing ensures we avoid overfitting our data.\n",
    "\n",
    "We will use some built-in functions provided by Magnitude that helps encode our classes/categories. We then partition our data into our train and test sets. For each set we have both data and labels. Initially, we will be making these partitions small to make iterating through model development much quicker. However, once the models are developed, we will expand our datasets to include all of our data. To ensure we defined our data correctly, we can print a few lines from the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ehr_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiovascular\n",
      "First line of train/test data:\n",
      "\t ['return', 'clinic', '4', 'weeks5']\n",
      "\t 0 Cardiovascular\n",
      "\t ['smokes', 'one', 'pack', 'per', 'day']\n",
      "\t 0 Cardiovascular\n",
      "Second line of train/test data:\n",
      "\t ['biceps', 'tendon', 'nonsubluxable']\n",
      "\t 1 Other\n",
      "\t ['denies', 'illicit', 'drug', 'use', 'family', 'history', 'parents', 'died', 'myocardial', 'infarctions']\n",
      "\t 1 Other\n"
     ]
    }
   ],
   "source": [
    "add_intent, intent_to_int, int_to_intent = MagnitudeUtils.class_encoding()\n",
    "\n",
    "x_train = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[:60000]]\n",
    "x_test = [ehr_sent[1].split(' ') for ehr_sent in ehr_sentences[60001:]]\n",
    "\n",
    "y_train = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[:60000]]\n",
    "y_test = [add_intent(ehr_sent[0]) for ehr_sent in ehr_sentences[60001:]]\n",
    "\n",
    "y_train = list(np.array(y_train).reshape(len(y_train)))\n",
    "y_test = list(np.array(y_test).reshape(len(y_test)))\n",
    "\n",
    "num_training = len(x_train)\n",
    "num_test = len(x_test)\n",
    "num_outputs = int(max(max(y_train), max(y_test))) + 1\n",
    "\n",
    "print(int_to_intent(0))\n",
    "\n",
    "print(\"First line of train/test data:\")\n",
    "print(\"\\t\", x_train[0])\n",
    "print(\"\\t\", y_train[0], int_to_intent(y_train[0]))\n",
    "print(\"\\t\", x_test[0])\n",
    "print(\"\\t\", y_test[0], int_to_intent(y_test[0]))\n",
    "print(\"Second line of train/test data:\")\n",
    "print(\"\\t\", x_train[1])\n",
    "print(\"\\t\", y_train[1], int_to_intent(y_train[1]))\n",
    "print(\"\\t\", x_test[1])\n",
    "print(\"\\t\", y_test[1], int_to_intent(y_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Custom Callback Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 163, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 241,202\n",
      "Trainable params: 241,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "STD_DEV = 0.01 # Deviation of noise for Gaussian Noise applied to the embeddings\n",
    "DROPOUT_RATIO = .5 # The ratio to dropout\n",
    "BATCH_SIZE = 100 # The number of examples per train/validation step\n",
    "EPOCHS = 100 # The number of times to repeat through all of the training data\n",
    "LEARNING_RATE = .01 # The learning rate for the optimizer\n",
    "HIDDEN_UNITS = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(STD_DEV, input_shape=(MAX_WORDS, med_vectors.dim)))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_UNITS, activation='tanh'), merge_mode='concat'))\n",
    "model.add(Dropout(DROPOUT_RATIO))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Batches and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1246s 2s/step - loss: 0.3444 - acc: 0.8653 - f1: 0.8653 - val_loss: 0.3224 - val_acc: 0.8725 - val_f1: 0.8725\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 431s 719ms/step - loss: 0.3141 - acc: 0.8740 - f1: 0.8740 - val_loss: 0.3103 - val_acc: 0.8762 - val_f1: 0.8762\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 435s 725ms/step - loss: 0.3063 - acc: 0.8775 - f1: 0.8774 - val_loss: 0.3043 - val_acc: 0.8804 - val_f1: 0.8804\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 431s 718ms/step - loss: 0.3012 - acc: 0.8810 - f1: 0.8810 - val_loss: 0.3001 - val_acc: 0.8824 - val_f1: 0.8824\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 434s 723ms/step - loss: 0.2951 - acc: 0.8829 - f1: 0.8829 - val_loss: 0.2948 - val_acc: 0.8852 - val_f1: 0.8852\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 432s 721ms/step - loss: 0.2896 - acc: 0.8857 - f1: 0.8857 - val_loss: 0.2911 - val_acc: 0.8853 - val_f1: 0.8853\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 434s 723ms/step - loss: 0.2846 - acc: 0.8867 - f1: 0.8867 - val_loss: 0.2902 - val_acc: 0.8850 - val_f1: 0.8850\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.2801 - acc: 0.8894 - f1: 0.8894 - val_loss: 0.2871 - val_acc: 0.8859 - val_f1: 0.8859\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.2754 - acc: 0.8905 - f1: 0.8905 - val_loss: 0.2867 - val_acc: 0.8853 - val_f1: 0.8853\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.2712 - acc: 0.8917 - f1: 0.8917 - val_loss: 0.2853 - val_acc: 0.8856 - val_f1: 0.8856\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 431s 718ms/step - loss: 0.2654 - acc: 0.8944 - f1: 0.8944 - val_loss: 0.2852 - val_acc: 0.8873 - val_f1: 0.8873\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 430s 716ms/step - loss: 0.2609 - acc: 0.8964 - f1: 0.8964 - val_loss: 0.2836 - val_acc: 0.8878 - val_f1: 0.8878\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 429s 715ms/step - loss: 0.2570 - acc: 0.8973 - f1: 0.8973 - val_loss: 0.2877 - val_acc: 0.8882 - val_f1: 0.8882\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 431s 718ms/step - loss: 0.2534 - acc: 0.8982 - f1: 0.8981 - val_loss: 0.2837 - val_acc: 0.8885 - val_f1: 0.8885\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 432s 719ms/step - loss: 0.2488 - acc: 0.9002 - f1: 0.9002 - val_loss: 0.2835 - val_acc: 0.8890 - val_f1: 0.8890\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 430s 717ms/step - loss: 0.2437 - acc: 0.9020 - f1: 0.9019 - val_loss: 0.2847 - val_acc: 0.8888 - val_f1: 0.8888\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 429s 714ms/step - loss: 0.2399 - acc: 0.9032 - f1: 0.9032 - val_loss: 0.2849 - val_acc: 0.8888 - val_f1: 0.8888\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 429s 714ms/step - loss: 0.2364 - acc: 0.9048 - f1: 0.9048 - val_loss: 0.2876 - val_acc: 0.8886 - val_f1: 0.8886\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 428s 714ms/step - loss: 0.2305 - acc: 0.9063 - f1: 0.9063 - val_loss: 0.2906 - val_acc: 0.8874 - val_f1: 0.8874\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 429s 714ms/step - loss: 0.2271 - acc: 0.9073 - f1: 0.9073 - val_loss: 0.2880 - val_acc: 0.8882 - val_f1: 0.8882\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 429s 715ms/step - loss: 0.2247 - acc: 0.9090 - f1: 0.9089 - val_loss: 0.2899 - val_acc: 0.8886 - val_f1: 0.8886\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 432s 719ms/step - loss: 0.2214 - acc: 0.9095 - f1: 0.9095 - val_loss: 0.2917 - val_acc: 0.8858 - val_f1: 0.8858\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.2138 - acc: 0.9130 - f1: 0.9130 - val_loss: 0.2978 - val_acc: 0.8842 - val_f1: 0.8842\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 433s 721ms/step - loss: 0.2095 - acc: 0.9140 - f1: 0.9139 - val_loss: 0.3033 - val_acc: 0.8822 - val_f1: 0.8822\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 432s 721ms/step - loss: 0.2101 - acc: 0.9141 - f1: 0.9141 - val_loss: 0.3062 - val_acc: 0.8833 - val_f1: 0.8833\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.2046 - acc: 0.9160 - f1: 0.9159 - val_loss: 0.3130 - val_acc: 0.8821 - val_f1: 0.8821\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 427s 711ms/step - loss: 0.1984 - acc: 0.9175 - f1: 0.9174 - val_loss: 0.3246 - val_acc: 0.8828 - val_f1: 0.8828\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 435s 725ms/step - loss: 0.1951 - acc: 0.9176 - f1: 0.9176 - val_loss: 0.3201 - val_acc: 0.8814 - val_f1: 0.8814\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 430s 716ms/step - loss: 0.1910 - acc: 0.9204 - f1: 0.9204 - val_loss: 0.3313 - val_acc: 0.8800 - val_f1: 0.8800\n",
      "Epoch 30/100\n",
      "439/600 [====================>.........] - ETA: 1:50 - loss: 0.1847 - acc: 0.9235 - f1: 0.9235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 430s 717ms/step - loss: 0.1790 - acc: 0.9253 - f1: 0.9252 - val_loss: 0.3496 - val_acc: 0.8787 - val_f1: 0.8787\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 430s 716ms/step - loss: 0.1801 - acc: 0.9245 - f1: 0.9245 - val_loss: 0.3473 - val_acc: 0.8788 - val_f1: 0.8788\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.1748 - acc: 0.9263 - f1: 0.9263 - val_loss: 0.3555 - val_acc: 0.8756 - val_f1: 0.8756\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.1712 - acc: 0.9277 - f1: 0.9277 - val_loss: 0.3570 - val_acc: 0.8778 - val_f1: 0.8778\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.1687 - acc: 0.9279 - f1: 0.9279 - val_loss: 0.3738 - val_acc: 0.8740 - val_f1: 0.8740\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.1659 - acc: 0.9289 - f1: 0.9289 - val_loss: 0.3748 - val_acc: 0.8701 - val_f1: 0.8701\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 376s 627ms/step - loss: 0.1625 - acc: 0.9306 - f1: 0.9305 - val_loss: 0.3805 - val_acc: 0.8704 - val_f1: 0.8704\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 323s 538ms/step - loss: 0.1595 - acc: 0.9320 - f1: 0.9320 - val_loss: 0.3948 - val_acc: 0.8732 - val_f1: 0.8732\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 321s 536ms/step - loss: 0.1577 - acc: 0.9321 - f1: 0.9321 - val_loss: 0.3909 - val_acc: 0.8755 - val_f1: 0.8755\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 330s 549ms/step - loss: 0.1558 - acc: 0.9331 - f1: 0.9331 - val_loss: 0.3868 - val_acc: 0.8731 - val_f1: 0.8731\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 316s 527ms/step - loss: 0.1535 - acc: 0.9342 - f1: 0.9341 - val_loss: 0.4022 - val_acc: 0.8677 - val_f1: 0.8677\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 315s 525ms/step - loss: 0.1493 - acc: 0.9355 - f1: 0.9355 - val_loss: 0.4220 - val_acc: 0.8707 - val_f1: 0.8707\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 316s 526ms/step - loss: 0.1454 - acc: 0.9376 - f1: 0.9376 - val_loss: 0.4251 - val_acc: 0.8723 - val_f1: 0.8723\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 320s 533ms/step - loss: 0.1461 - acc: 0.9374 - f1: 0.9374 - val_loss: 0.4162 - val_acc: 0.8694 - val_f1: 0.8694\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 320s 534ms/step - loss: 0.1437 - acc: 0.9383 - f1: 0.9383 - val_loss: 0.4332 - val_acc: 0.8693 - val_f1: 0.8693\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 321s 535ms/step - loss: 0.1393 - acc: 0.9391 - f1: 0.9391 - val_loss: 0.4449 - val_acc: 0.8707 - val_f1: 0.8707\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 321s 535ms/step - loss: 0.1408 - acc: 0.9387 - f1: 0.9387 - val_loss: 0.4363 - val_acc: 0.8659 - val_f1: 0.8659\n",
      "Epoch 49/100\n",
      " 41/600 [=>............................] - ETA: 4:52 - loss: 0.1438 - acc: 0.9393 - f1: 0.9393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 320s 534ms/step - loss: 0.1371 - acc: 0.9406 - f1: 0.9406 - val_loss: 0.4438 - val_acc: 0.8689 - val_f1: 0.8689\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 317s 529ms/step - loss: 0.1348 - acc: 0.9418 - f1: 0.9417 - val_loss: 0.4617 - val_acc: 0.8705 - val_f1: 0.8705\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 313s 522ms/step - loss: 0.1332 - acc: 0.9416 - f1: 0.9416 - val_loss: 0.4566 - val_acc: 0.8686 - val_f1: 0.8686\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 314s 523ms/step - loss: 0.1313 - acc: 0.9428 - f1: 0.9428 - val_loss: 0.4769 - val_acc: 0.8667 - val_f1: 0.8667\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 316s 526ms/step - loss: 0.1290 - acc: 0.9446 - f1: 0.9446 - val_loss: 0.4847 - val_acc: 0.8621 - val_f1: 0.8621\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 320s 534ms/step - loss: 0.1275 - acc: 0.9440 - f1: 0.9440 - val_loss: 0.4710 - val_acc: 0.8629 - val_f1: 0.8629\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 178s 297ms/step - loss: 0.1264 - acc: 0.9448 - f1: 0.9448 - val_loss: 0.4893 - val_acc: 0.8695 - val_f1: 0.8695\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 175s 291ms/step - loss: 0.1221 - acc: 0.9472 - f1: 0.9472 - val_loss: 0.5003 - val_acc: 0.8679 - val_f1: 0.8679\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 176s 293ms/step - loss: 0.1239 - acc: 0.9447 - f1: 0.9446 - val_loss: 0.4862 - val_acc: 0.8667 - val_f1: 0.8667\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 174s 289ms/step - loss: 0.1228 - acc: 0.9473 - f1: 0.9473 - val_loss: 0.4966 - val_acc: 0.8690 - val_f1: 0.8690\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 178s 296ms/step - loss: 0.1202 - acc: 0.9465 - f1: 0.9465 - val_loss: 0.4976 - val_acc: 0.8652 - val_f1: 0.8652\n",
      "Epoch 62/100\n",
      " 90/600 [===>..........................] - ETA: 2:22 - loss: 0.1206 - acc: 0.9478 - f1: 0.9478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 178s 297ms/step - loss: 0.1144 - acc: 0.9500 - f1: 0.9500 - val_loss: 0.4963 - val_acc: 0.8686 - val_f1: 0.8686\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 176s 293ms/step - loss: 0.1095 - acc: 0.9517 - f1: 0.9517 - val_loss: 0.5010 - val_acc: 0.8668 - val_f1: 0.8668\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 178s 297ms/step - loss: 0.1087 - acc: 0.9518 - f1: 0.9518 - val_loss: 0.5434 - val_acc: 0.8674 - val_f1: 0.8674\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 176s 293ms/step - loss: 0.1083 - acc: 0.9526 - f1: 0.9525 - val_loss: 0.5189 - val_acc: 0.8652 - val_f1: 0.8652\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 178s 296ms/step - loss: 0.1062 - acc: 0.9531 - f1: 0.9530 - val_loss: 0.5315 - val_acc: 0.8654 - val_f1: 0.8654\n",
      "Epoch 76/100\n",
      "190/600 [========>.....................] - ETA: 1:54 - loss: 0.1114 - acc: 0.9523 - f1: 0.9523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 176s 294ms/step - loss: 0.1007 - acc: 0.9562 - f1: 0.9562 - val_loss: 0.5477 - val_acc: 0.8652 - val_f1: 0.8652\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 178s 297ms/step - loss: 0.0998 - acc: 0.9564 - f1: 0.9564 - val_loss: 0.5633 - val_acc: 0.8649 - val_f1: 0.8649\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 177s 295ms/step - loss: 0.1015 - acc: 0.9546 - f1: 0.9545 - val_loss: 0.5503 - val_acc: 0.8667 - val_f1: 0.8667\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 179s 298ms/step - loss: 0.0991 - acc: 0.9566 - f1: 0.9566 - val_loss: 0.5381 - val_acc: 0.8676 - val_f1: 0.8676\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 177s 295ms/step - loss: 0.1017 - acc: 0.9556 - f1: 0.9556 - val_loss: 0.5467 - val_acc: 0.8664 - val_f1: 0.8664\n",
      "Epoch 89/100\n",
      "307/600 [==============>...............] - ETA: 1:23 - loss: 0.0973 - acc: 0.9567 - f1: 0.9567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 177s 295ms/step - loss: 0.0952 - acc: 0.9582 - f1: 0.9582 - val_loss: 0.5813 - val_acc: 0.8680 - val_f1: 0.8680\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 179s 298ms/step - loss: 0.0960 - acc: 0.9582 - f1: 0.9582 - val_loss: 0.5682 - val_acc: 0.8684 - val_f1: 0.8684\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 178s 297ms/step - loss: 0.0944 - acc: 0.9585 - f1: 0.9585 - val_loss: 0.5741 - val_acc: 0.8693 - val_f1: 0.8693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dbc18fbe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_batches = MagnitudeUtils.batchify(x_train, y_train, BATCH_SIZE) # Split the training data into batches\n",
    "num_batches_per_epoch_train = int(np.ceil(num_training/float(BATCH_SIZE)))\n",
    "test_batches = MagnitudeUtils.batchify(x_test, y_test, BATCH_SIZE)  # Split the test data into batches\n",
    "num_batches_per_epoch_test = int(np.ceil(num_test/float(BATCH_SIZE)))\n",
    "\n",
    "\n",
    "# Generates batches of the transformed training data\n",
    "train_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_train_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_train_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_train_batch, y_train_batch in training_batches\n",
    ")\n",
    "\n",
    "# Generates batches of the transformed test data\n",
    "test_batch_generator = (\n",
    "  (\n",
    "    med_vectors.query(x_test_batch), # Magnitude will handle converting the 2D array of text into the 3D word vector representations!\n",
    "    MagnitudeUtils.to_categorical(y_test_batch, num_outputs) # Magnitude will handle converting the class labels into one-hot encodings!\n",
    "  ) for x_test_batch, y_test_batch in test_batches\n",
    ")\n",
    "\n",
    "# Start training\n",
    "model.fit_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps_per_epoch = num_batches_per_epoch_train,\n",
    "    validation_data = test_batch_generator,\n",
    "    validation_steps = num_batches_per_epoch_test,\n",
    "    epochs = EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after training for 100 epochs:\n",
      "loss: 0.0875 - categorical_accuracy: 0.9604 - f1: 0.9604\n",
      "val_loss: 0.5741 - val_categorical_accuracy: 0.8693 - f1: 0.8693\n"
     ]
    }
   ],
   "source": [
    "print(\"Results after training for %d epochs:\" % (EPOCHS,))\n",
    "\n",
    "train_metrics = model.evaluate_generator(\n",
    "    generator = train_batch_generator,\n",
    "    steps = num_batches_per_epoch_train,\n",
    ")\n",
    "\n",
    "print(\"loss: %.4f - categorical_accuracy: %.4f - f1: %.4f\" % tuple(train_metrics))\n",
    "\n",
    "val_metrics = model.evaluate_generator(\n",
    "    generator = test_batch_generator,\n",
    "    steps = num_batches_per_epoch_test,\n",
    ")\n",
    "\n",
    "print(\"val_loss: %.4f - val_categorical_accuracy: %.4f - f1: %.4f\" % tuple(val_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular', 'Other']\n",
      "[[ 781  896]\n",
      " [ 534 8729]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Cardiovascular       0.59      0.47      0.52      1677\n",
      "         Other       0.91      0.94      0.92      9263\n",
      "\n",
      "   avg / total       0.86      0.87      0.86     10940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(med_vectors.query(x_test)), axis=1)\n",
    "class_labels = [int_to_intent(y) for y in set(y_test)] \n",
    "report = classification_report(y_test, y_pred, target_names=class_labels)\n",
    "print(class_labels)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2da40767f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = [int_to_intent(y_class) for y_class in unique_labels(y_test, y_pred)]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "#     fig.set_figheight(15)\n",
    "#     fig.set_figwidth(15)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_labels\n",
    "                      , title='Confusion Matrix for Cardiovascular Disease LSTM Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
